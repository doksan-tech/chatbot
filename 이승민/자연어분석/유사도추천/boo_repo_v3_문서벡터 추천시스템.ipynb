{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09-11 문서 벡터를 이용한 추천 시스템\n",
    "(Recommendation System using Document Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운로드 링크 : https://drive.google.com/file/d/15Q7DZ7xrJsI2Hji-WbkU9j1mwnODBd5A/view?usp=sharing\n",
    "\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "import gzip\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서의 수 : 2382\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 데이터프레임으로 로드하고 전체 문서의 수를 출력\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/data.csv\", filename=\"data.csv\")\n",
    "df = pd.read_csv(\"bookdata.csv\")\n",
    "print('전체 문서의 수 :',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_link</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We know that power is shifting: From West to E...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moisés Naím</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.63</td>\n",
       "      <td>The End of Power: From Boardrooms to Battlefie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Following the success of The Accidental Billio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Blake J. Harris</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.94</td>\n",
       "      <td>Console Wars: Sega, Nintendo, and the Battle t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How to tap the power of social software and ne...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Chris Brogan</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.78</td>\n",
       "      <td>Trust Agents: Using the Web to Build Influence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>William J. Bernstein is an American financial ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>William J. Bernstein</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>The Four Pillars of Investing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Amazing book. And I joined Steve Jobs and many...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Akio Morita</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>Made in Japan: Akio Morita and Sony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                                               Desc  \\\n",
       "0             0  We know that power is shifting: From West to E...   \n",
       "1             1  Following the success of The Accidental Billio...   \n",
       "2             2  How to tap the power of social software and ne...   \n",
       "3             3  William J. Bernstein is an American financial ...   \n",
       "4             4  Amazing book. And I joined Steve Jobs and many...   \n",
       "\n",
       "   Unnamed: 0                author     genre  \\\n",
       "0         0.0           Moisés Naím  Business   \n",
       "1         1.0       Blake J. Harris  Business   \n",
       "2         2.0          Chris Brogan  Business   \n",
       "3         3.0  William J. Bernstein  Business   \n",
       "4         4.0           Akio Morita  Business   \n",
       "\n",
       "                                          image_link  rating  \\\n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...    3.63   \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...    3.94   \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...    3.78   \n",
       "3  https://i.gr-assets.com/images/S/compressed.ph...    4.20   \n",
       "4  https://i.gr-assets.com/images/S/compressed.ph...    4.05   \n",
       "\n",
       "                                               title  \n",
       "0  The End of Power: From Boardrooms to Battlefie...  \n",
       "1  Console Wars: Sega, Nintendo, and the Battle t...  \n",
       "2  Trust Agents: Using the Web to Build Influence...  \n",
       "3                      The Four Pillars of Investing  \n",
       "4                Made in Japan: Akio Morita and Sony  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상위 5개의 행만 출력\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 줄거리에 해당하는 열인 'Desc 열'이 중요\n",
    "# 해당 열에 있는 데이터에 대해서 Word2Vec을 학습하기 위해 전처리를 진행\n",
    "# 해당 열에 대해서 전처리를 수행하고 'cleaned'라는 열에 저장\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text \n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df['cleaned'] = df['Desc'].apply(_removeNonAscii)\n",
    "df['cleaned'] = df.cleaned.apply(make_lower_case)\n",
    "df['cleaned'] = df.cleaned.apply(remove_stop_words)\n",
    "df['cleaned'] = df.cleaned.apply(remove_punctuation)\n",
    "df['cleaned'] = df.cleaned.apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    know power shifting west east north south pres...\n",
       "1    following success accidental billionaires mone...\n",
       "2    tap power social software networks build busin...\n",
       "3    william j bernstein american financial theoris...\n",
       "4    amazing book joined steve jobs many akio morit...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상위 5개의 행만 출력\n",
    "df['cleaned'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서의 수 : 2381\n"
     ]
    }
   ],
   "source": [
    "# 빈 값이 생긴 행이 있다면, nan 값으로 변환 후에 해당 행을 제거\n",
    "df['cleaned'].replace('', np.nan, inplace=True)\n",
    "df = df[df['cleaned'].notna()]\n",
    "print('전체 문서의 수 :',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화를 수행하여 corpus라는 리스트에 저장\n",
    "# 해당 리스트 corpus를 통해 Word2Vec을 훈련\n",
    "corpus = []\n",
    "for words in df['cleaned']:\n",
    "    corpus.append(words.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 사전 훈련된 워드 임베딩 사용하기\n",
    "\n",
    "- 사전 훈련된 Word2Vec을 로드하고 초기 단어 벡터값으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # urllib.request.urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", \\\n",
    "# #                            filename=\"GoogleNews-vectors-negative300.bin.gz\")\n",
    "\n",
    "# f = open('./data/GoogleNews-vectors-negative300.bin','rb')\n",
    "# data = f.read()    # bytes\n",
    "\n",
    "# word2vec_model = Word2Vec(vector_size = 300, window=5, min_count = 2, workers = -1)\n",
    "# word2vec_model.build_vocab(corpus)\n",
    "# word2vec_model.wv.intersect_word2vec_format('GoogleNews-vectors-negative300.bin', lockf=1.0, binary=True)\n",
    "# word2vec_model.train(corpus, total_examples = word2vec_model.corpus_count, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b6f0d8d647a14ce7aec9650edf6792f5fc61b159b6795cf61c93c7b5c41aef5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
