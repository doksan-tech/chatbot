{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import random, sys, os, glob, json, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용되고 있는 문자 수:  82\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m char_indices \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((c, i) \u001b[39mfor\u001b[39;00m i, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(chars)) \u001b[39m# 문자 -> ID\u001b[39;00m\n\u001b[1;32m     18\u001b[0m indices_char \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((i, c) \u001b[39mfor\u001b[39;00m i, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(chars)) \u001b[39m# ID -> 문자\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mprint\u001b[39m(char_indices[:\u001b[39m50\u001b[39;49m])\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# 대화 파일 불러오기\n",
    "data_dir = './dialogue'\n",
    "for dir in os.listdir(data_dir):\n",
    "    dir_path = data_dir + '/' + dir\n",
    "    if not os.path.isdir(dir_path): continue\n",
    "    files = glob.glob(dir_path + '/*.txt')\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = re.sub('^[0-9] : ', '', text, flags=re.MULTILINE)\n",
    "            # print(text[:10])\n",
    "            # sys.exit(0)\n",
    "            # 문자를 하나하나 읽어들이고 ID 붙이기\n",
    "            chars = sorted(list(set(text)))\n",
    "            print('사용되고 있는 문자 수: ', len(chars))\n",
    "            char_indices = dict((c, i) for i, c in enumerate(chars)) # 문자 -> ID\n",
    "            indices_char = dict((i, c) for i, c in enumerate(chars)) # ID -> 문자\n",
    "            print(char_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'군생활 생각난다'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'kakao2', 'kakao4', 'kakao3', 'kakao1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import random, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "fp = codecs.open('data/BEXX0003.txt', encoding='utf-16')\n",
    "soup = BeautifulSoup(fp, 'html.parser')\n",
    "body = soup.select_one('body')\n",
    "text = body.getText() + ' '\n",
    "print('코퍼스 길이: ', len(text))\n",
    "\n",
    "# 문자를 하나하나 읽어들이고 ID 붙이기\n",
    "chars = sorted(list(set(text)))\n",
    "print('사용되고 있는 문자 수: ', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars)) # 문자 -> ID\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars)) # ID -> 문자\n",
    "\n",
    "# 텍스트를 maxlen 개의 문자로 자르고 다음에 오는 문자 등록하기\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('학습할 구문의 수: ', len(sentences))\n",
    "print('텍스트를 ID 벡터로 변환합니다....')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print('x shape=', X.shape)\n",
    "# LSTM 모델 구축\n",
    "print('모델을 구축합니다.')\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(128, input_dim=maxlen * len(chars)))\n",
    "#model.add(Dense(len(chars)))\n",
    "#model.add(Activation('softmax'))\n",
    "model = Sequential([\n",
    "    Input(shape=(maxlen, len(chars))),\n",
    "    LSTM(128),\n",
    "    Dense(len(chars), activation='softmax')\n",
    "    ])\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# 후보를 배열에서 꺼내기\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "# 학습 생성 반복\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('반복=', iteration)\n",
    "    model.fit(X, y, batch_size=128, epochs=1)\n",
    "\n",
    "    # 임의의 시작 텍스트 선택\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    # 다양한 문장 생성\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('---다양성 = ', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print(f'---시드 = \"{sentence}\"')\n",
    "        sys.stdout.write(generated)\n",
    "        # 시드를 기반으로 텍스트 자동 생성\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "            # 다음에 올 문자 예측\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            # 출력\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6fb0ca7c3bd8bc698549aa02a9df33484cafacf9c2c862385157fe6bff41776c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
