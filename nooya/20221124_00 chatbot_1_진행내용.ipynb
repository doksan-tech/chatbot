{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝을 이용한 chatbot 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 알고가기\n",
    "\n",
    "- 하나의 기능을 수행하는 코드들 집합\n",
    "- 반복 수행하는 코드들을 기능 단위로 묶어서 재사용할 수 있도록 구성\n",
    "- 짤 짜인 함수는 하나의 목적, 함수명으로 그 함수 역할 유추할 수 있어야 함\n",
    "\n",
    "- 사용자 정의 함수, 내장함수, 외장함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 함수 \n",
    "\n",
    "- 사용자가 직접 만든 함수 \n",
    "\n",
    "- def 함수명(인자):\n",
    "\n",
    "      코드\n",
    "      \n",
    "      코드\n",
    "      \n",
    "      ...\n",
    "      return 결괏값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 반환 함수print('name: %s' % user.name)\n",
    "def add(a, b):\n",
    "    return a*b\n",
    "\n",
    "add(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 / value:1\n",
      "index: 1 / value:2\n",
      "index: 2 / value:3\n",
      "index: 3 / value:4\n",
      "index: 4 / value:5\n"
     ]
    }
   ],
   "source": [
    "# enumerate() 함수\n",
    "# 순서가 있는 자료형(리스트, 튜플, 문자열) 입력하면 인덱스 포함한 요솟값을 반환\n",
    "# for 반복문 이용, 편하게 인덱스 활용\n",
    "numbers = [1, 2, 3, 4, 5] \n",
    "for idx, value in enumerate(numbers):\n",
    "    print('index: {} / value:{}'.format(idx, value)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k/to/gra/junn/jaes'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str() \n",
    "# 입력으로 들어온 데이터를 문자열 객체 반환\n",
    "\n",
    "# join()\n",
    "# 리스트 포함된 요소들을 지정한 구분자로 구분해 문자열 반환\n",
    "# 리스트낸 요소들을 문자열로 합칠 때 사용\n",
    "names = ['k','to','gra','junn','jaes']\n",
    "','.join(names) \n",
    "'/'.join(names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k', 'to', 'gra', 'junn', 'jaes']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split() \n",
    "# join 과 반대. 문자열을 특정 구분자 기준 분리해 리스트 반환\n",
    "names = ['k','to','gra','junn','jaes']\n",
    "names_str = ','.join(names) \n",
    "names_split = names_str.split(',') \n",
    "names_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"
     ]
    }
   ],
   "source": [
    "# find() 특정 문자열 찾는 함수\n",
    "\n",
    "# strip() \n",
    "# 주어진 문자열 양쪽 끝 공백 제거 함수\n",
    "\n",
    "# filter()\n",
    "# 개별 요소를 반복적으로 셀 수 있는 객체 입력받아 각 요소를 함수로 수행한 후 결과 True 묶어 반환\n",
    "def in_even(number):\n",
    "    return number % 2 == 0    # 짝수 True 반환 \n",
    "\n",
    "numbers = range(1, 21)\n",
    "even_list = list(filter(in_even, numbers))\n",
    "print(even_list)  \n",
    "\n",
    "# list 생성자는 생략 가능한 하나 인자 가지며, 인자로 들어온 데이터(객체) 리스트로 반환\n",
    "# filter() filter객체 형태로 반환하기 때문에 결과를 리스트 형태로 사용 못함. 리스트 형태로 사용하려면 list 생성자 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"
     ]
    }
   ],
   "source": [
    "# lambda 키워드\n",
    "# lambda는 함수 생성할 때 사용하는 키워드.\n",
    "# def 보다 간결하게 함수 정의. 익명 함수. > heap 메모리 영역에서 삭제되어 메모리 관리에 효율적\n",
    "numbers = range(1, 21)\n",
    "even_list = list(filter(lambda n: n%2==0, numbers))\n",
    "print(even_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16]\n",
      "[1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "# map()\n",
    "# 개별요소를 반복적으로 셀 수 있는 객체를 입력받아 각 요소를 함수로 수행한 후 결과를 묶어 반환\n",
    "# 바로 계산 X 게으른 연산 > 메모리 절약 \n",
    "def square(number):\n",
    "    return number ** 2\n",
    "\n",
    "numbers = range(1, 5) \n",
    "square_list = list(map(square, numbers)) \n",
    "print(square_list) \n",
    "\n",
    "# lambda 이용\n",
    "numbers = range(1, 5) \n",
    "s_list = list(map(lambda x: x**2, numbers)) \n",
    "print(s_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 외장함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle\n",
    "# 파이썬 객체를 파일로 저장하고 메모리로 읽어올 수 있도록 도와주는 모듈\n",
    "# 객체를 메모리에 저장해 놓은 상황에서 프로그램이 종료되면 객체 내용이 사라짐\n",
    "# 프로그램 재실행시켰을 때도 유지되어야 하는 객체가 있다면 pickle 모듈 사용해 파일로 저장하고 읽어오면 됨\n",
    "# pickle 모듈 dump() 함수 이용해 리스트와 딕셔너리 객체 파일로 저장\n",
    "import pickle \n",
    "f = open('setting.txt', 'wb')  # open() 함수 이용 setting.txt 파일을 바이너리 쓰기(wb) 모드로 파일을 읽을 수 있는 파일 객체 반환\n",
    "setting = [{'title': 'python program'}, {'author':'kei'}]   # 프로그램 설정 값 들어 있는 딕셔너리 요소로 가지는 리스트 정의\n",
    "pickle.dump(setting, f) # 리스트 객체 setting 내용을 파일 객체 f 에 저장 \n",
    "f.close()   # 파일 객체 f 닫음, 반드시 닫아줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'python program'}, {'author': 'kei'}]\n"
     ]
    }
   ],
   "source": [
    "# pickle 모듈 load() 함수 이용 파일 저장된 리스트 , 딕셔너리 객체를 메모리로 읽어와 출력\n",
    "import pickle\n",
    "f = open('setting.txt', 'rb') \n",
    "setting = pickle.load(f) \n",
    "f.close() \n",
    "print(setting) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1669260105.2847102"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time 모듈\n",
    "# 시스템이 제공하는 시간과 관련된 유용한 함수 포함\n",
    "# time.time() \n",
    "import time\n",
    "time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2022, tm_mon=11, tm_mday=24, tm_hour=12, tm_min=22, tm_sec=13, tm_wday=3, tm_yday=328, tm_isdst=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time.localtime() \n",
    "import time\n",
    "time.localtime(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022/11/24 12:24:30'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time.strftime('시간포매팅')\n",
    "# 원하는 형태로 날짜와 시간을 출력\n",
    "# time.strftime('시간포매팅', time.localtime(time.time())) \n",
    "import time\n",
    "lt = time.localtime(time.time()) \n",
    "time.strftime('%Y/%m/%d %H:%M:%S', lt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6969182323020202"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random() 모듈\n",
    "# 난숫값 생성\n",
    "# random.random()\n",
    "\n",
    "# random.uniform() \n",
    "# 임의 생성 되는 실수의 범위 제한 \n",
    "import random \n",
    "random.uniform(1, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random.randint() \n",
    "# 2개 인자로 난수 범위 지정해서 정수 난수 생성\n",
    "import random\n",
    "random.randint(1, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스\n",
    "- 인스턴스를 만들기 위해 필요한 설계도\n",
    "- 메서드와 인스턴스 변수 정의\n",
    "\n",
    "## 생성자 및 소멸자\n",
    "- 인스턴스 생성될 때 자동으로 호출되는 생성자 메서드 제공\n",
    "- __ init __ \n",
    "\n",
    "class 클래스명:\n",
    "\n",
    "    def __init__(self, 인자, ...):\n",
    "    ...\n",
    "\n",
    "- __ del __ \n",
    "\n",
    "class 클래스명:\n",
    "\n",
    "    def __del__(self):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메서드와 인스턴스 변수\n",
    "\n",
    "- 메서드: 객체의 행동 정의\n",
    "- 인스턴스 변수: 객체 상태 표현\n",
    "- 클래스 내부 사용 함수 = 메서드, 전역적 사용 변수 = 인스턴스 변수\n",
    "\n",
    "class 클래스명:\n",
    "\n",
    "    def 메서드명(self, 인자):\n",
    "        \n",
    "        코드\n",
    "\n",
    "        코드\n",
    "        ...\n",
    "\n",
    "self.변수명 = 초깃값        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value = 100\n",
      "a = 200, b = 50, c = 200, d=50.0\n"
     ]
    }
   ],
   "source": [
    "# 사칙 연산 클래스 \n",
    "class calc:    \n",
    "    def __init__(self, init_value):   # calc 클래스 생성자 정의.  생성자 = 메서드. 일반 함수와 같은 특성 - 반드시 첫 번째 인자 self 사용 > self 안하면 내부 존재 메서드 인식 X\n",
    "        self.value = init_value       # 생성자 함수 내부.생성자에서 받은 인자로 인스턴스 변수 초기화. \n",
    "        \n",
    "    def add(self, n):           # 덧셈 메서드 정의. calc 클래스 메서드라 첫 번째 인자로 self 키워드 사용\n",
    "        return self.value + n    # 덧셈 메서드 내부. \n",
    "    \n",
    "    def sub(self, n):\n",
    "        return self.value - n \n",
    "    \n",
    "    def mul(self, n):\n",
    "        return self.value * n \n",
    "    \n",
    "    def div(self, n):\n",
    "        return self.value / n   \n",
    "    \n",
    "cal = calc(100)                 # calc 클래스 인스턴스 생성하면서 인자로 초깃값 100 입력 > 초깃값 100은 생성자 인자 init_value에 저장\n",
    "print('value = {0}'.format(cal.value))   \n",
    "\n",
    "a = cal.add(100) \n",
    "b = cal.sub(50) \n",
    "c = cal.mul(2) \n",
    "d = cal.div(2) \n",
    "\n",
    "print('a = {0}, b = {1}, c = {2}, d={3}'.format(a, b, c, d)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter3. 토크나이징\n",
    "\n",
    "## 3.1 토크나이징 소개 \n",
    "\n",
    "- 자연어 처리 (Natural Language Processing) : NLP\n",
    "\n",
    "- 토큰(token) : 가장 기본이 되는 단어들\n",
    "    - 일정한 의미가 있는 가장 작은 정보 단위\n",
    "\n",
    "- 토크나이징: 주어진 문장에서 토큰 단위로 정보를 나누는 작업 \n",
    "    - 문장 형태 데이터 처리 위해 제일 처음 수행하는 기본 작업\n",
    "    - 텍스트 전처리 과정 사용\n",
    "\n",
    "## 3.2 KoNLPY\n",
    "\n",
    "- 한국어 자연어 처리 위한 파이썬 라이브러리 = 코엔엘파이\n",
    "\n",
    "- 형태소(morpheme): 토큰 단위 사용, 일정 의미 있는 가장 작은 말의 단위. 더 이상 쪼개지지 않는 단어\n",
    "    - 형태소를 토큰 단위로 사용하면 단어와 품사 정보를 같이 활용 할 수 있어 효과적\n",
    "    - 한국어: 명사, 조사를 띄어 쓰지 않고 용언에 따라 여러 가지 의미가 붙기 때문에 띄어쓰기만으로 토크나이징 불가\n",
    "    - 형태소 분석기 필요 . 형태소, 어근, 접두사/접미사, 품사 등 언어속성 구조 파악 \n",
    "        - 문장에서 형태소 추출하면서 형태소 뜻과 문맥 고려해 품사 태깅해 줌\n",
    "        - 품사: 단어를 의미나 형식 기능에 따라 분류한 것\n",
    "        - 한국어 9품사: 명사, 대명사, 수사, 동사, 형용사, 관형사, 부사, 조사, 감탄사\n",
    "\n",
    "\n",
    "### 3.2.1 Kkma\n",
    "\n",
    "- 꼬꼬마: GPL v2 라이선스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kkma 모듈 함수 \n",
    "\n",
    "- morphs(phrase): 인자로 입력한 문장을 형태소 단위로 토크나이징. 토크나이징된 형태소들 리스트 형태로 반환\n",
    "- nouns(phrase) : 인자로 입력한 문장에서 품사가 명사인 토큰만 추출\n",
    "- pos(phrase, flatten=True): POS tagger 부르며, 인자로 입력한 문장에서 형태소 추출하고 품사 태깅. 형태소와 품사가 튜플 형태 묶여 리스트 반환 \n",
    "- sentences(phrase): 인자로 입력한 여러 문장을 분리. 분리된 문장은 리스트 형태로 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['승', '민', '이', '늘', 'ㄴ', '크', '게', '성공', '하', 'ㄴ다', '.']\n",
      "[('승', 'NNG'), ('민', 'NNG'), ('이', 'JKS'), ('늘', 'VV'), ('ㄴ', 'ETD'), ('크', 'VA'), ('게', 'ECD'), ('성공', 'NNG'), ('하', 'XSV'), ('ㄴ다', 'EFN'), ('.', 'SF')]\n",
      "['승', '승민', '민', '성공']\n",
      "['오늘 날씨가 어 때? 내일 춥다 던데. 옷 따듯하게 입어.']\n"
     ]
    }
   ],
   "source": [
    "# 토크나이징 예제 \n",
    "from konlpy.tag import Kkma \n",
    "\n",
    "# 꼬꼬마 형태소 분석기 객체 생성\n",
    "kkma = Kkma()\n",
    "\n",
    "text = '승민이는 크게 성공한다.' \n",
    "\n",
    "# 형태소 추출 \n",
    "morphs = kkma.morphs(text) \n",
    "print(morphs) \n",
    "\n",
    "# 형태소와 품사 태그 추출\n",
    "pos = kkma.pos(text) \n",
    "print(pos) \n",
    "\n",
    "# 명사만 추출\n",
    "nouns = kkma.nouns(text) \n",
    "print(nouns) \n",
    "\n",
    "# 문장 분리 \n",
    "sentences = '오늘 날씨가 어때? 내일 춥다던데. 옷 따듯하게 입어.' \n",
    "s = kkma.sentences(sentences) \n",
    "print(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 Komoran\n",
    "\n",
    "- Shineware 에서 자바로 개발한 한국어 형태소 분석기\n",
    "- 공백이 포함된 형태소 단위로도 분석 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Komoran 함수 \n",
    "\n",
    "- morphs(phrase): 인자로 입력한 문장을 형태소 단위로 토크나이징. 형태소들은 리스트 반환 \n",
    "- nouns(phrase): 인자로 입력한 문장에서 품사가 명사인 토큰들만 추출 \n",
    "- pos(phrase, flatten=True): POS tagger. 인자로 입력한 문장에서 형태소를 추출한 뒤 품사 태깅. 형태소와 품사가 튜플 형태 리스트 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['승', '민이', '는', '크', '게', '성공', '하', 'ㄴ다', '.']\n",
      "[('승', 'NNG'), ('민이', 'NNP'), ('는', 'JX'), ('크', 'VA'), ('게', 'EC'), ('성공', 'NNG'), ('하', 'XSV'), ('ㄴ다', 'EF'), ('.', 'SF')]\n",
      "['승', '민이', '성공']\n"
     ]
    }
   ],
   "source": [
    "# 토크나이징 예제 \n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "# 코모란 형태소 분석기 객체 생성\n",
    "komoran = Komoran()\n",
    "\n",
    "text = '승민이는 크게 성공한다.' \n",
    "\n",
    "# 형태소 추출 \n",
    "morphs = komoran.morphs(text) \n",
    "print(morphs) \n",
    "\n",
    "# 형태소와 품사 태그 추출\n",
    "pos = komoran.pos(text) \n",
    "print(pos) \n",
    "\n",
    "# 명사만 추출\n",
    "nouns = komoran.nouns(text) \n",
    "print(nouns)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3 Okt \n",
    "\n",
    "- 트위터 개발한 한국어 처리기에서 파생된 오픈 소스\n",
    "- 띄어쓰기 어느 정도 되어 있는 문장을 빠르게 분석할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okt 모듈 함수 \n",
    "\n",
    "- morphs(phrase): 인자로 입력한 문장을 형태소 단위로 토크나이징. 리스트 반환\n",
    "- nuouns(phrase): 인자로 입력한 문장에서 품사 명사인 토큰들만 추출\n",
    "- pos(phrase, stem=False, join=False): POS tagger. 인자로 입력한 문장에서 형태소 추출하고 품사 태깅. 튜플 묶여서 리스트 반환 \n",
    "- normalize(phrase): 입력한 문장 정규화.\n",
    "- phrases(phrase): 입력한 문장에서 어구 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['승민', '이', '는', '크게', '성공한다', '.']\n",
      "[('승민', 'Noun'), ('이', 'Suffix'), ('는', 'Josa'), ('크게', 'Noun'), ('성공한다', 'Adjective'), ('.', 'Punctuation')]\n",
      "['승민', '크게']\n",
      "오늘 날씨가 좋아요ㅋㅋ\n",
      "['오늘', '오늘 날씨', '좋아욬', '날씨']\n"
     ]
    }
   ],
   "source": [
    "# 토크나이징 예제 \n",
    "from konlpy.tag import Okt \n",
    "\n",
    "# okt 형태소 분석기 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "text = '승민이는 크게 성공한다.' \n",
    "\n",
    "# 형태소 추출 \n",
    "morphs = okt.morphs(text) \n",
    "print(morphs) \n",
    "\n",
    "# 형태소와 품사 태그 추출\n",
    "pos = okt.pos(text) \n",
    "print(pos) \n",
    "\n",
    "# 명사만 추출\n",
    "nouns = okt.nouns(text) \n",
    "print(nouns)\n",
    "\n",
    "# 정규화, 어구 추출\n",
    "text = '오늘 날씨가 좋아욬ㅋㅋ'\n",
    "print(okt.normalize(text))\n",
    "print(okt.phrases(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4 사용자 사전 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('우리', 'NP'), ('챗봇은', 'NA'), ('엔', 'NNB'), ('엘', 'NNP'), ('피', 'NNG'), ('를', 'JKO'), ('좋ㅇ아해.', 'NA')]\n"
     ]
    }
   ],
   "source": [
    "# 미등록 단어 형태소 분석 \n",
    "from konlpy.tag import Komoran \n",
    "\n",
    "komoran = Komoran() \n",
    "text = '우리 챗봇은 엔엘피를 좋ㅇ아해.' \n",
    "pos = komoran.pos(text) \n",
    "print(pos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('우리', 'NP'), ('챗봇은', 'NA'), ('엔', 'NNB'), ('엘', 'NNP'), ('피', 'NNG'), ('를', 'JKO'), ('좋아하', 'VV'), ('아', 'EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran \n",
    "\n",
    "komoran = Komoran(userdic = './user_dic.tsv')\n",
    "text = '우리 챗봇은 엔엘피를 좋아해.' \n",
    "pos = komoran.pos(text) \n",
    "print(pos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.임베딩\n",
    "\n",
    "### 4.1 임베딩이란?\n",
    "\n",
    "- 자연어를 숫자나 벡터 형태로 변환하는 과정 . 수치화해 벡터 공간으로 표현\n",
    "\n",
    "- 문장임베딩과 단어임베딩\n",
    "\n",
    "\n",
    "### 4.2 단어임베딩 \n",
    "\n",
    "#### 4.2.1 원-핫 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '날씨', '구름']\n",
      "{'오늘': 0, '날씨': 1, '구름': 2}\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np \n",
    "\n",
    "komoran = Komoran() \n",
    "text = '오늘 날씨는 구름이 많아요.' \n",
    "\n",
    "# 명사만 추출 \n",
    "nouns = komoran.nouns(text) \n",
    "print(nouns) \n",
    "\n",
    "# 단어 사전 구축 및 단어별 인덱스 부여 \n",
    "dics = {}\n",
    "for word in nouns:\n",
    "    if word not in dics.keys(): \n",
    "        dics[word] = len(dics) \n",
    "print(dics) \n",
    "\n",
    "# 원 - 핫 인코딩 \n",
    "nb_classes = len(dics) \n",
    "targets = list(dics.values()) \n",
    "one_hot_targets = np.eye(nb_classes)[targets]  \n",
    "print(one_hot_targets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 희소 표현과 분산 표현 \n",
    "\n",
    "- 원 - 핫 인코딩: 표현하는 단어 인덱스 요소만 1, 나머지 요소 모두 0 = 희소 벡터(희소 행렬) > 희소 표현\n",
    "\n",
    "- 분산표현: 단어 간 유사성 잘 표현하면서 벡터 공간을 절약할 수 있는 방법 \n",
    "    - 하나 차원에 다양한 정보\n",
    "    - 밀집표현(밀집벡터) \n",
    "\n",
    "\n",
    "#### 4.2.3 Word2Vec\n",
    "\n",
    "- 신경망 기반 단어 임베딩의 대표 방법 \n",
    "    - CBOW(continuous bag-of-words) : 맥락(주변단어) 이용해 타깃 단어를 예측하는 신경망 모델 -> 학습 속도 빠름\n",
    "        \n",
    "    - skip-gram : 하나의 타깃 단어를 이용해 주변 단어들을 예측하는 신경망 모델 -> 임베딩 품질 우수\n",
    "\n",
    "    - 윈도우: 타깃 단어 예측위해 앞뒤 단어 확인. 앞뒤로 몇개 단어까지 확인할지 결정하는 범위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec 실습 파일 별도 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 텍스트 유사도 \n",
    "\n",
    "### 5.1 텍스트 유사도 개요\n",
    "\n",
    "### 5.2 n-gram 유사도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '트리니티'), ('트리니티', '입학'), ('입학',))\n",
      "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '대학교'), ('대학교', '입학'), ('입학',))\n",
      "0.6666666666666666\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# n-gram 유사도 계산 \n",
    "\n",
    "from konlpy.tag import Komoran \n",
    "\n",
    "# 어절 단위 n-gram \n",
    "# 튜풀 형태 반환. 슬라이싱 이용해 문장을 어절 단위로  n개씩 끊어서 토큰 저장 \n",
    "def word_ngram(bow, num_gram):\n",
    "    text = tuple(bow) \n",
    "    ngrams = [text[x:x + num_gram] for x in range(0, len(text))]\n",
    "    return tuple(ngrams) \n",
    "\n",
    "# 유사도 계산 \n",
    "# 1의 토큰이 2의 토큰과 얼마나 동일한지 횟수 카운트.\n",
    "# 카운트된 값을 1의 전체 토큰 수로 나누면 유사도 계산 \n",
    "# 1.0에 가까울수록 1과 유사해짐\n",
    "def similarity(doc1, doc2):\n",
    "    cnt = 0\n",
    "    for token in doc1:\n",
    "        if token in doc2:\n",
    "            cnt += 1\n",
    "    return cnt/len(doc1) \n",
    "\n",
    "# 문장 정의\n",
    "sentence1 = '6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다' \n",
    "sentence2 = '6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다' \n",
    "sentence3 = '나는 맛있는 점심을 뉴턴 선생님과 함께 먹었다' \n",
    "\n",
    "# 형태소 분석기에서 명사(단어) 추출 \n",
    "# Komoran 형태소 분석기를 이용해 정의된 문장에서 명사를 리스트 형태로 추출 \n",
    "komoran = Komoran() \n",
    "bow1 = komoran.nouns(sentence1)\n",
    "bow2 = komoran.nouns(sentence2)\n",
    "bow3 = komoran.nouns(sentence3) \n",
    "\n",
    "# 단어 n-gram 토큰 추출 \n",
    "# 처음 정의한 word_ngram() 함수를 이용해 명사 리스트의 n-gram 토큰을 추출 \n",
    "# word_ngram() 함수 num_gram 인자에 2를 입력했으므로 2-gram 방식으로 토큰 추출 \n",
    "doc1 = word_ngram(bow1, 2)    # 2-gram 방식으로 추출  \n",
    "doc2 = word_ngram(bow2, 2)\n",
    "doc3 = word_ngram(bow3, 2)\n",
    "\n",
    "# 추출된 n-gram 토큰 출력 \n",
    "print(doc1) \n",
    "print(doc2) \n",
    "\n",
    "# 유사도 계산 \n",
    "r1 = similarity(doc1, doc2) \n",
    "r2 = similarity(doc3, doc1) \n",
    "\n",
    "# 계산된 유사도 출력 \n",
    "print(r1) \n",
    "print(r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 1, '입학': 1, '대학교': 0, '점심': 0, '선생': 0, '님과 함께': 0}\n",
      "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 0, '입학': 1, '대학교': 1, '점심': 0, '선생': 0, '님과 함께': 0}\n",
      "{'6월': 0, '뉴턴': 1, '선생님': 0, '제안': 0, '트리니티': 0, '입학': 0, '대학교': 0, '점심': 1, '선생': 1, '님과 함께': 1}\n",
      "0.8333333333333335\n",
      "0.20412414523193154\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran \n",
    "import numpy as np \n",
    "from numpy import dot    \n",
    "from numpy.linalg import norm \n",
    "\n",
    "# 코사인 유사도 계산\n",
    "# 넘파이 벡터 내적 계산하는 함수와 노름(norm) 계산하는 함수 이용\n",
    "# dot() 함수는 인자로 들어온 2개의 넘파이 배열을 내적곱 한다\n",
    "# norm() 함수는 벡터 크기 나태내느 수학 용어.\n",
    "# L2 노름(유클리드 노름) 주로 사용 \n",
    "def cos_sim(vec1, vec2):\n",
    "    return dot(vec1, vec2) / (norm(vec1) * norm(vec2)) \n",
    "\n",
    "# TDM 만들기\n",
    "# 비교 문장에서 추출한 단어 사전을 기준으로 문장에 해당 단어들이 얼마나 포함되어 있는지 나타내는 단어 문서 행렬(TDM) 만드느 함수\n",
    "def make_term_doc_mat(sentence_bow, word_dics):\n",
    "    freq_mat = {} \n",
    "    \n",
    "    for word in word_dics:\n",
    "        freq_mat[word] = 0 \n",
    "    \n",
    "    for word in word_dics:\n",
    "        if word in sentence_bow:\n",
    "            freq_mat[word] += 1 \n",
    "            \n",
    "    return freq_mat \n",
    "\n",
    "# 단어 벡터 만들기\n",
    "# 단어 문서 행렬에서 표현된 토큰들의 출현 빈도 데이터를 벡터로 만들어 주는 함수 \n",
    "def make_vector(tdm):\n",
    "    vec = [] \n",
    "    for key in tdm:\n",
    "        vec.append(tdm[key]) \n",
    "    return vec \n",
    "\n",
    "# 문장 정의 \n",
    "sentence1 = '6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다' \n",
    "sentence2 = '6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다' \n",
    "sentence3 = '나는 맛있는 점심을 뉴턴 선생님과 함께 먹었다' \n",
    "\n",
    "# 형태소 분석기를 이용해 단어 묶음 리스트 생성 \n",
    "# Komoran 형태소 분석기 이용해 정의된 문장에서 명사를 리스트 형태로 추출 \n",
    "komoran = Komoran() \n",
    "bow1 = komoran.nouns(sentence1) \n",
    "bow2 = komoran.nouns(sentence2) \n",
    "bow3 = komoran.nouns(sentence3) \n",
    "\n",
    "# 단어 묶음 리스트를 하나로 합침 \n",
    "# 3개 문장에서 추출한 단어 리스트를 하나 리스트로 합침 \n",
    "bow = bow1 + bow2 + bow3 \n",
    "\n",
    "# 단어 묶음에서 중복을 제거해 단어 사전 구축 \n",
    "# 하나로 합쳐진 단어 묶음 리스트에서 중복된 단어를 제거해 새로운 단어 리스트 구축 \n",
    "word_dics = [] \n",
    "for token in bow: \n",
    "    if token not in word_dics:\n",
    "        word_dics.append(token) \n",
    "        \n",
    "# 문장별 단어 문서 행렬 계산 \n",
    "freq_list1 = make_term_doc_mat(bow1, word_dics) \n",
    "freq_list2 = make_term_doc_mat(bow2, word_dics) \n",
    "freq_list3 = make_term_doc_mat(bow3, word_dics) \n",
    "print(freq_list1) \n",
    "print(freq_list2) \n",
    "print(freq_list3)\n",
    "\n",
    "# 문장 벡터 생성 \n",
    "# 각 문장마다 벡터를 생성해 넘파이 배열로 변환. 처음 만든 코사인 유사도 함수의 인자는 반드시 넘파이 배열로 넘겨야 함\n",
    "doc1 = np.array(make_vector(freq_list1)) \n",
    "doc2 = np.array(make_vector(freq_list2))\n",
    "doc3 = np.array(make_vector(freq_list3))\n",
    "\n",
    "# 코사인 유사도 계산 \n",
    "# 문장1과 문장2 유사도 계산\n",
    "r1 = cos_sim(doc1, doc2) \n",
    "r2 = cos_sim(doc3, doc1) \n",
    "print(r1) \n",
    "print(r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 챗봇 엔진에 필요한 딥러닝 모델 \n",
    "\n",
    "### 6.1 케라스 정리 \n",
    "### 6.2 딥러닝 분류모델 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 분류 모델 학습 \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.datasets import mnist \n",
    "from  tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten, Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "Epoch 1/10\n",
      "2100/2100 [==============================] - 15s 6ms/step - loss: 0.8323 - accuracy: 0.7561 - val_loss: 0.3804 - val_accuracy: 0.8870\n",
      "Epoch 2/10\n",
      "2100/2100 [==============================] - 11s 5ms/step - loss: 0.3519 - accuracy: 0.8972 - val_loss: 0.3018 - val_accuracy: 0.9101\n",
      "Epoch 3/10\n",
      "2100/2100 [==============================] - 11s 5ms/step - loss: 0.3018 - accuracy: 0.9123 - val_loss: 0.2760 - val_accuracy: 0.9193\n",
      "Epoch 4/10\n",
      "2100/2100 [==============================] - 14s 7ms/step - loss: 0.2760 - accuracy: 0.9188 - val_loss: 0.2625 - val_accuracy: 0.9276\n",
      "Epoch 5/10\n",
      "2100/2100 [==============================] - 10s 5ms/step - loss: 0.2520 - accuracy: 0.9265 - val_loss: 0.2399 - val_accuracy: 0.9324\n",
      "Epoch 6/10\n",
      "2100/2100 [==============================] - 10s 5ms/step - loss: 0.2315 - accuracy: 0.9325 - val_loss: 0.2239 - val_accuracy: 0.9349\n",
      "Epoch 7/10\n",
      "2100/2100 [==============================] - 11s 5ms/step - loss: 0.2215 - accuracy: 0.9353 - val_loss: 0.2037 - val_accuracy: 0.9418\n",
      "Epoch 8/10\n",
      "2100/2100 [==============================] - 10s 5ms/step - loss: 0.2028 - accuracy: 0.9411 - val_loss: 0.1972 - val_accuracy: 0.9439\n",
      "Epoch 9/10\n",
      "2100/2100 [==============================] - 10s 5ms/step - loss: 0.1933 - accuracy: 0.9444 - val_loss: 0.1940 - val_accuracy: 0.9464\n",
      "Epoch 10/10\n",
      "2100/2100 [==============================] - 12s 5ms/step - loss: 0.1815 - accuracy: 0.9470 - val_loss: 0.1761 - val_accuracy: 0.9502\n",
      "모델 평가\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1864 - accuracy: 0.9447\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST 데이터셋 가져오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # 데이터 정규화(픽셀값 범위 0 ~ 255) \n",
    "\n",
    "# tf.data를 사용하여 데이터셋을 섞고 배치 만들기\n",
    "# 배치사이즈 20. 배치사이즈는 학습 시 샘플 수를 의미하며, 배치 사이즈가 작을 수록 가중치 갱신 자주 일어남. \n",
    "# 배치사이즈는 전체 학습 데이터셋보다 작거나 동일해얗 함\n",
    "ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000)\n",
    "train_size = int(len(x_train) * 0.7) # 학습셋:검증셋 = 7:3\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).batch(20)\n",
    "\n",
    "# MNIST 분류 모델 구성\n",
    "# 입력층 1개와 은닉층 2개, 출력층 1개 \n",
    "# Flatten() = 2차원 이미지 1차원으로 평탄화 = 784\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 생성\n",
    "# 손실함수 = sparse_categorical_crossentropy(다중 클래스 분류) \n",
    "# 오차보정 옵티마이저 = SGD\n",
    "# 모델 성능 = accuracy\n",
    "# 손실함수 : 모델의 결괏값과 실제 정답과의 오차를 계산하는 함수 \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "# fit(학습데이터셋, 검증데이터셋, 에포크랎) \n",
    "# epoch = 학습 수행 값(클수록 과적합 높아짐) \n",
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "# 모델 평가\n",
    "# evaluate(테스트용 데이터셋) \n",
    "print('모델 평가')\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "# 모델 정보 화면에 출력\n",
    "# 모델 구성 요소(계층 종류, 출력 형태) \n",
    "model.summary()\n",
    "\n",
    "# 모델 저장\n",
    "# 심층 신경망 학습 시간 길다. > 해당 모델 사용할 때마다 학스 하면 시간 한정.\n",
    "# 신경망 구성, 가중치, 상태 정보 등이 저장\n",
    "model.save('mnist_model.h5')\n",
    "\n",
    "# 학습 결과 그래프 그리기\n",
    "# 손실값, 학습 정확도  \n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 학습된 딥러닝 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 오류 발생\n",
    "# predicted = model.predict_classes(token_list, verbose=0)\n",
    "\n",
    "# # 오류 해결\n",
    "# y_prob = model.predict(token_list, verbose=0) \n",
    "# predicted = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 - 1s - loss: 0.1864 - accuracy: 0.9447 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손글씨 이미지 예측값 :  [9]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터셋 가져오기\n",
    "_, (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test / 255.0 # 데이터 정규화\n",
    "\n",
    "# 모델 불러오기\n",
    "model = load_model('mnist_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# 테스트셋에서 20번째 이미지 출력\n",
    "plt.imshow(x_test[20], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# 테스트셋의 20번째 이미지 클래스 분류\n",
    "picks = [20]\n",
    "p_prob = model.predict(x_test[picks], verbose=0)\n",
    "predicted = p_prob.argmax(axis = 1)  \n",
    "print(\"손글씨 이미지 예측값 : \", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 문장 분류를 위한 CNN 모델\n",
    "\n",
    "- 합성곱 신경망 \n",
    "- 이미지 좋은 성능\n",
    "- 합성곱, 풀링 연산\n",
    "\n",
    "### 6.2.2 챗봇 문답 데이터 감정 분류 모델 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 감정 분류 CNN 모델 \n",
    "\n",
    "# 모듈 임포트 \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import preprocessing \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "414/414 [==============================] - 34s 68ms/step - loss: 0.8977 - accuracy: 0.5626 - val_loss: 0.5676 - val_accuracy: 0.8122\n",
      "Epoch 2/5\n",
      "414/414 [==============================] - 31s 73ms/step - loss: 0.5296 - accuracy: 0.8017 - val_loss: 0.3051 - val_accuracy: 0.9052\n",
      "Epoch 3/5\n",
      "414/414 [==============================] - 34s 81ms/step - loss: 0.3163 - accuracy: 0.8969 - val_loss: 0.1644 - val_accuracy: 0.9518\n",
      "Epoch 4/5\n",
      "414/414 [==============================] - 30s 72ms/step - loss: 0.2085 - accuracy: 0.9370 - val_loss: 0.0875 - val_accuracy: 0.9695\n",
      "Epoch 5/5\n",
      "414/414 [==============================] - 24s 59ms/step - loss: 0.1397 - accuracy: 0.9575 - val_loss: 0.0689 - val_accuracy: 0.9788\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9721\n",
      "Accuracy: 97.208124\n",
      "loss: 0.089912\n"
     ]
    }
   ],
   "source": [
    "# 데이턱 읽어오기 \n",
    "# pandas reda_csv() 함수 이용해 파일 읽어와 CNN 모델 학습 필요한 Q(질문), label(감정) 데이터를 features, labels 리스트 저장 \n",
    "train_file = './data/ChatbotData.csv'\n",
    "data = pd.read_csv(train_file, delimiter=',') \n",
    "features = data['Q'].tolist() \n",
    "labels = data['label'].tolist() \n",
    "\n",
    "# 단어 인덱스 시퀀스 벡터 \n",
    "# 위에서 불러온 질문 리스트(features) 에서 문장 하나씩 꺼내와 text_to_word_sequence() 함수 이용해 단어 시퀀스 만듦\n",
    "# 단어시퀀스 = 단어 토큰들의 순차적 리스트 의미 \n",
    "# 단어 시퀀스를 말뭉치(corpus) 리스트에 저장\n",
    "# 텐서플로 토크나이저 texts_to_sequences() 함수 이용해 문장 내 모든 단어를 시퀀스 번호로 변환 \n",
    "# 변환된 시퀀스 번호 이용해 단어 임베딩 벡터 만들\n",
    "# 시퀀스 번호로 만든 벡터 문제: 문장 길이가 제각각 벡터 크기 다름 > CNN 모델 입력층 고정된 개수 입력 노드 가짐 \n",
    "# 시퀀스 번호로 변환된 전체 벡터 크기를 동일하게 맞춰줘야 함\n",
    "# MAX_SEQ_LEN = 15 보다 작은 벡터에는 남는 공간 생김 여길 0으로 채우는 작업 = 패딩 처리 \n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features] \n",
    "tokenizer = preprocessing.text.Tokenizer() \n",
    "tokenizer.fit_on_texts(corpus) \n",
    "sequences = tokenizer.texts_to_sequences(corpus) \n",
    "word_index = tokenizer.word_index \n",
    "\n",
    "MAX_SEQ_LEN = 15  # 단어 시퀀스 벡터 크기 \n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post') \n",
    "\n",
    "# 학습용, 검증용, 테스트용 데이터셋 생성\n",
    "# 학습셋:검증셋:테스트셋 = 7:2:1 \n",
    "# 패딩처리된 시퀀스(padded_seq) 벡터 리스트와 감정 (labels) 리스트 전체를 데이터셋 객체로 만듦 \n",
    "# 데이터 랜덤 섞은 후 학습용, 검증용, 테스트용 데이터셋 7:2:1 나눠 실제 학습에 필요한 데이터셋 객체 분리 \n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels)) \n",
    "ds = ds.shuffle(len(features)) \n",
    "\n",
    "train_size = int(len(padded_seqs) * 0.7) \n",
    "val_size = int(len(padded_seqs) * 0.2) \n",
    "test_size = int(len(padded_seqs) * 0.1)\n",
    "\n",
    "train_ds = ds.take(train_size).batch(20) \n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20) \n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)  \n",
    "\n",
    "# 하이퍼파라미터 설정 \n",
    "dropout_prob = 0.5 \n",
    "EMB_SIZE = 128 \n",
    "EPOCH = 5 \n",
    "VOCAB_SIZE = len(word_index) + 1   # 전체 단어 수 \n",
    "\n",
    "# CNN 모델 정의 \n",
    "# 케라스 함수형 모델 방식으로 구현 \n",
    "# 문장을 감정 클래스로 분류하는 CNN 모델은 전처리된 입력 데이터를 단어 임베팅 처리하는 영역 / 합성곱 필터와 연산을 통해 문장의 특징 정보(특징맵) 추출하고 평탄화 하는 영역 \n",
    "# 완전 연결 계층 통해 감정별로 클래스 분류하는 영역\n",
    "\n",
    "# 단어 임베딩 영역 코드 \n",
    "# 입력 계층은 케라스 Input() 함수 생성 - shape 인자로 입력 노드에 들어올 데이터 형상 지정 \n",
    "input_layer = Input(shape = (MAX_SEQ_LEN)) \n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer) # 임베딩 계층 \n",
    "dropout_emb = Dropout(rate = dropout_prob)(embedding_layer) # 50% 확률로 Dropout() 생성 > 오버피팅 대비\n",
    "\n",
    "# 임베딩 벡터에서 특징 추출하는 영역 구현\n",
    "conv1 = Conv1D(\n",
    "    filters = 128,\n",
    "    kernel_size = 3, \n",
    "    padding = 'valid',\n",
    "    activation = tf.nn.relu)(dropout_emb) \n",
    "pool1 = GlobalMaxPool1D()(conv1)    # 최대 풀링 연산 수행\n",
    "\n",
    "conv2 = Conv1D(\n",
    "    filters = 128,\n",
    "    kernel_size = 4, \n",
    "    padding = 'valid',\n",
    "    activation = tf.nn.relu)(dropout_emb) \n",
    "pool2 = GlobalMaxPool1D()(conv2) \n",
    "\n",
    "conv3 = Conv1D(\n",
    "    filters = 128,\n",
    "    kernel_size = 5, \n",
    "    padding = 'valid',\n",
    "    activation = tf.nn.relu)(dropout_emb) \n",
    "pool3 = GlobalMaxPool1D()(conv3) \n",
    "\n",
    "# 3, 4, 5 - gram 이후 합치기 \n",
    "concat = concatenate([pool1, pool2, pool3]) # 병렬로 처리된 합성곱 계층 특징맵 결과를 하나로 묶어줌 \n",
    "\n",
    "# 완전 연결 계층 구현\n",
    "hidden = Dense(128, activation=tf.nn.relu)(concat)    # 128개 출력 노드, relu 활성화 함수 사용하는 Dense 계층 생성 3개의 특정맵 데이터 입력으로 ㅂ다음\n",
    "dropout_hidden = Dropout(rate = dropout_prob)(hidden) \n",
    "logits = Dense(3, name='logits')(dropout_hidden)      # 3가지 감정 분류. 출력노드 3개인 Dense() 생성. 활성화 함수 X logits = 점수\n",
    "predictions = Dense(3, activation=tf.nn.softmax)(logits)  # softmax = 확률계산 \n",
    "\n",
    "# 모델 생성 \n",
    "# 위에서 정의 한 계층들 케라스 모델에 추가하는 작업 \n",
    "model = Model(inputs=input_layer, outputs=predictions) \n",
    "model.compile(optimizer='adam',  # 최적화\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# 모델 학습 \n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, verbose=1) # (학습용, 검증용, 에포크, verbose = 1 이면 모델 학습 시 진행과정 보여줌)\n",
    "\n",
    "# 모델 평가 (테스트 데이터텟 이용) \n",
    "loss, accuracy = model.evaluate(test_ds, verbose=1) \n",
    "print('Accuracy: %f' % (accuracy * 100)) \n",
    "print('loss: %f' % (loss)) \n",
    "\n",
    "# 모델 저장 \n",
    "model.save('cnn_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9839\n",
      "Accuracy: 98.392552\n",
      "loss : 0.053448\n"
     ]
    }
   ],
   "source": [
    "# evaluate() 함수 이용해 성능 평가 \n",
    "# 테스트용 데이터 셋 이용 \n",
    "loss, accuracy = model.evaluate(test_ds, verbose = 1) \n",
    "print('Accuracy: %f' % (accuracy * 100))\n",
    "print('loss : %f' % (loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 완료 h5 파일 포맷으로 저장\n",
    "model.save('cnn_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 챗봇 문답 데이터 감정 분류 모델 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 15, 128)      1715072     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 15, 128)      0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 13, 128)      49280       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 12, 128)      65664       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 11, 128)      82048       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " global_max_pooling1d_6 (Global  (None, 128)         0           ['conv1d_6[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_7 (Global  (None, 128)         0           ['conv1d_7[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_8 (Global  (None, 128)         0           ['conv1d_8[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 384)          0           ['global_max_pooling1d_6[0][0]', \n",
      "                                                                  'global_max_pooling1d_7[0][0]', \n",
      "                                                                  'global_max_pooling1d_8[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          49280       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " logits (Dense)                 (None, 3)            387         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 3)            12          ['logits[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,961,743\n",
      "Trainable params: 1,961,743\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "100/100 - 2s - loss: 0.0553 - accuracy: 0.9870 - 2s/epoch - 20ms/step\n",
      "단어 시퀀스 : ['썸', '타는', '여자가', '남사친', '만나러', '간다는데', '뭐라', '해']\n",
      "단어 인덱스 시퀀스 : [   13    61   127  4320  1333 12162   856    31     0     0     0     0\n",
      "     0     0     0]\n",
      "문장 분류(정답) : 2\n",
      "1/1 [==============================] - 1s 556ms/step\n",
      "감정 예측 점수 : [[1.1164079e-05 3.0207676e-07 9.9998856e-01]]\n",
      "감정 예측 클래스 : [2]\n"
     ]
    }
   ],
   "source": [
    "# 문장 감정 분류 CNN 모델 사용 \n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "from tensorflow.keras.models import Model, load_model \n",
    "from tensorflow.keras import preprocessing \n",
    "\n",
    "# 데이터 읽어오기 \n",
    "# pandas read_csv() 함수 이용. ChatbotData.csv 파일 읽어와 label(감정) 분류할 Q(질문) 데이터 features 리스트에 저장. \n",
    "# label 리스트는 CNN 모델이 예측한 분류 결과와 실제 분류값을 비교하기 위한 목적 사용\n",
    "train_file = './data/ChatbotData.csv' \n",
    "data = pd.read_csv(train_file, delimiter=',') \n",
    "features = data['Q'].tolist() \n",
    "labels = data['label'].tolist() \n",
    "\n",
    "# 단어 인덱스 시퀀스 벡터 \n",
    "# 질문리스트 features 에서 한 문장씩 꺼내와 text_to_word_sequence() 함수 이용해 단어 시퀀스 만든 후 말뭉치(corpus) 리스트 저장 \n",
    "# tensorflow 토크나이저 texts_to_sequences() 함수 이용해 문장 내 모든 단어 시퀀스 번호로 변환 \n",
    "# 단어 시퀀스 벡터 크기 맞추기 위해 pad_sequences() 함수 사용하여 패딩 처리 \n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features] \n",
    "tokenizer = preprocessing.text.Tokenizer() \n",
    "tokenizer.fit_on_texts(corpus) \n",
    "sequences = tokenizer.texts_to_sequences(corpus) \n",
    "\n",
    "MAX_SEQ_LEN = 15   # 단어 시퀀스 벡터 크기 \n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding = 'post') \n",
    "\n",
    "# 테스트용 데이터셋 생성 \n",
    "# 위에서 처리한 시퀀스(padded_seqs) 벡터 리스트와 감정(labels) 리스트 전체를 데이터셋 객체로 만듦 \n",
    "# 데이터 랜덤으로 섞은 후 테스트용 데이터셋 2,000개 뽑아서 20개씩 처리 \n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels)) \n",
    "ds = ds.shuffle(len(features)) \n",
    "test_ds = ds.take(2000).batch(20)   # 테스트 데이터셋 \n",
    "\n",
    "# 감정 분류 CNN 모델 불러오기\n",
    "# 케라스 load_model() 함수 사용 모델 파일 불러오기 \n",
    "# 성공적 불러오면 학습 모델 객체 반환.\n",
    "# 파일 저장된 모델 정보 확인 summary() 함수 호출. 테스트셋 데이터 이용 모델 성틍 평가\n",
    "model = load_model('cnn_model.h5') \n",
    "model.summary() \n",
    "model.evaluate(test_ds, verbose = 2) \n",
    "\n",
    "#테스트용 데이터셋의 10212 번째 데이터 출력 \n",
    "# 망뭉치 데이터 리스트 10212번째 문장 감정 예측\n",
    "# 예측 앞서 데이터 확인\n",
    "print('단어 시퀀스 :', corpus[10212]) \n",
    "print('단어 인덱스 시퀀스 :', padded_seqs[10212]) \n",
    "print('문장 분류(정답) :', labels[10212]) \n",
    "\n",
    "# 테스트용 데이터셋의 10212번째 데이터 검증 예측 \n",
    "# 케라스 predict() 함수는 입력 데이터에 대해 각 클래스별로 예측한 점수를 반환\n",
    "# 텐서플로 argmax() 함수 이용해 분류 클래스들 중 예측 점수가 가장 큰 클래스 번호 계산 = 10212번째 문장이 어떤 감정 클래스에 포함되어 있는지 판단 \n",
    "picks = [10212] \n",
    "predict = model.predict(padded_seqs[picks]) \n",
    "predict_class = tf.math.argmax(predict, axis = 1) \n",
    "print('감정 예측 점수 :', predict) \n",
    "print('감정 예측 클래스 :', predict_class.numpy()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3 개체명 인식을 위한 양방향 LSTM 모델 \n",
    "\n",
    "### 6-3-1 RNN (순환신경망) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape x:(185, 15) / y: (185,)\n",
      "train_x.shape = (185, 15, 1)\n",
      "train_y.shape = (185,)\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 5s 7ms/step - loss: 0.8418\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7175\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6084\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5212\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4436\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3733\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3102\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2502\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1991\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1603\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1370\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1211\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1081\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0980\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0913\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0850\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0794\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0743\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0692\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0646\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0603\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0561\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0522\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0484\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0449\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0415\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0384\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0353\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0325\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0297\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0273\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0250\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0226\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0206\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0187\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0169\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0153\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0138\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0125\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0114\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0104\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0095\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0087\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0080\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0075\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0069\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0065\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0057\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0054\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0046\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0044\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0042\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0037\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0035\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0032\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0030\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0029\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0023\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0021\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0019\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0019\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0018\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0018\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0017\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0017\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0015\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0015\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0014\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0012\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0012\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0012\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0011\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0011\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0010\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0010\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.8871e-04\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.6061e-04\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.3262e-04\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.1142e-04\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.8958e-04\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.5686e-04\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.3889e-04\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.2157e-04\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7.9639e-04\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.7565e-04\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.5279e-04\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.3274e-04\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.1404e-04\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.9661e-04\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.7856e-04\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.6053e-04\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.5108e-04\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.2773e-04\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.2343e-04\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.0296e-04\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5.8918e-04\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.7240e-04\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6000e-04\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4392e-04\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.3339e-04\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2524e-04\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5.0490e-04\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9659e-04\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8849e-04\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.8042e-04\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6774e-04\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5424e-04\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.4194e-04\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3471e-04\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.2255e-04\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1347e-04\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0335e-04\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.9572e-04\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.8746e-04\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7939e-04\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7341e-04\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.6416e-04\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.5975e-04\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4980e-04\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.4272e-04\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3883e-04\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3732e-04\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.2547e-04\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1912e-04\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1355e-04\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0522e-04\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0013e-04\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.9540e-04\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8744e-04\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9059e-04\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.8305e-04\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7540e-04\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6810e-04\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.6488e-04\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.5920e-04\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5837e-04\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5003e-04\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4768e-04\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.4137e-04\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.3935e-04\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3596e-04\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2968e-04\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.2779e-04\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2474e-04\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.2274e-04\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.1828e-04\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1405e-04\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1017e-04\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0804e-04\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0769e-04\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0580e-04\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9712e-04\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9450e-04\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.9504e-04\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9028e-04\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8774e-04\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8134e-04\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8012e-04\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7872e-04\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7521e-04\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7266e-04\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7017e-04\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6810e-04\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6714e-04\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6371e-04\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.6449e-04\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6269e-04\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6543e-04\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.6150e-04\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5766e-04\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5199e-04\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5012e-04\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4642e-04\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4503e-04\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3996e-04\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3831e-04\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3864e-04\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3565e-04\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3377e-04\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3278e-04\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3875e-04\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2818e-04\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2294e-04\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2418e-04\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2397e-04\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2062e-04\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1840e-04\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1607e-04\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1437e-04\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1382e-04\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1156e-04\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1120e-04\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1101e-04\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1077e-04\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0461e-04\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0459e-04\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0197e-04\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0116e-04\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0229e-04\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.9847e-05\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.7384e-05\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.5608e-05\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.4262e-05\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.2775e-05\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.3879e-05\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.8847e-05\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.9458e-05\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.8074e-05\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.8181e-05\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 9.0339e-05\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 9.1228e-05\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.4188e-05\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.3036e-05\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.2729e-05\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.1175e-05\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.8775e-05\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.8363e-05\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7.9977e-05\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.8280e-05\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.9526e-05\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.5685e-05\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.3078e-05\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.2429e-05\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.7650e-05\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.2570e-05\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.0922e-05\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.2746e-05\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.9917e-05\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.8649e-05\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.7787e-05\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.8070e-05\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.2038e-05\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.7591e-05\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.3699e-05\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.8934e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,) (1, 1) 0 15\n",
      "(16,) (1, 1) 1 16\n",
      "(17,) (1, 1) 2 17\n",
      "(18,) (1, 1) 3 18\n",
      "(19,) (1, 1) 4 19\n",
      "(20,) (1, 1) 5 20\n",
      "(21,) (1, 1) 6 21\n",
      "(22,) (1, 1) 7 22\n",
      "(23,) (1, 1) 8 23\n",
      "(24,) (1, 1) 9 24\n",
      "(25,) (1, 1) 10 25\n",
      "(26,) (1, 1) 11 26\n",
      "(27,) (1, 1) 12 27\n",
      "(28,) (1, 1) 13 28\n",
      "(29,) (1, 1) 14 29\n",
      "(30,) (1, 1) 15 30\n",
      "(31,) (1, 1) 16 31\n",
      "(32,) (1, 1) 17 32\n",
      "(33,) (1, 1) 18 33\n",
      "(34,) (1, 1) 19 34\n",
      "(35,) (1, 1) 20 35\n",
      "(36,) (1, 1) 21 36\n",
      "(37,) (1, 1) 22 37\n",
      "(38,) (1, 1) 23 38\n",
      "(39,) (1, 1) 24 39\n",
      "(40,) (1, 1) 25 40\n",
      "(41,) (1, 1) 26 41\n",
      "(42,) (1, 1) 27 42\n",
      "(43,) (1, 1) 28 43\n",
      "(44,) (1, 1) 29 44\n",
      "(45,) (1, 1) 30 45\n",
      "(46,) (1, 1) 31 46\n",
      "(47,) (1, 1) 32 47\n",
      "(48,) (1, 1) 33 48\n",
      "(49,) (1, 1) 34 49\n",
      "(50,) (1, 1) 35 50\n",
      "(51,) (1, 1) 36 51\n",
      "(52,) (1, 1) 37 52\n",
      "(53,) (1, 1) 38 53\n",
      "(54,) (1, 1) 39 54\n",
      "(55,) (1, 1) 40 55\n",
      "(56,) (1, 1) 41 56\n",
      "(57,) (1, 1) 42 57\n",
      "(58,) (1, 1) 43 58\n",
      "(59,) (1, 1) 44 59\n",
      "(60,) (1, 1) 45 60\n",
      "(61,) (1, 1) 46 61\n",
      "(62,) (1, 1) 47 62\n",
      "(63,) (1, 1) 48 63\n",
      "(64,) (1, 1) 49 64\n",
      "(65,) (1, 1) 50 65\n",
      "(66,) (1, 1) 51 66\n",
      "(67,) (1, 1) 52 67\n",
      "(68,) (1, 1) 53 68\n",
      "(69,) (1, 1) 54 69\n",
      "(70,) (1, 1) 55 70\n",
      "(71,) (1, 1) 56 71\n",
      "(72,) (1, 1) 57 72\n",
      "(73,) (1, 1) 58 73\n",
      "(74,) (1, 1) 59 74\n",
      "(75,) (1, 1) 60 75\n",
      "(76,) (1, 1) 61 76\n",
      "(77,) (1, 1) 62 77\n",
      "(78,) (1, 1) 63 78\n",
      "(79,) (1, 1) 64 79\n",
      "(80,) (1, 1) 65 80\n",
      "(81,) (1, 1) 66 81\n",
      "(82,) (1, 1) 67 82\n",
      "(83,) (1, 1) 68 83\n",
      "(84,) (1, 1) 69 84\n",
      "(85,) (1, 1) 70 85\n",
      "(86,) (1, 1) 71 86\n",
      "(87,) (1, 1) 72 87\n",
      "(88,) (1, 1) 73 88\n",
      "(89,) (1, 1) 74 89\n",
      "(90,) (1, 1) 75 90\n",
      "(91,) (1, 1) 76 91\n",
      "(92,) (1, 1) 77 92\n",
      "(93,) (1, 1) 78 93\n",
      "(94,) (1, 1) 79 94\n",
      "(95,) (1, 1) 80 95\n",
      "(96,) (1, 1) 81 96\n",
      "(97,) (1, 1) 82 97\n",
      "(98,) (1, 1) 83 98\n",
      "(99,) (1, 1) 84 99\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sin 곡선 예측 RNN 모델 사용 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM, SimpleRNN \n",
    "\n",
    "# time step 만큼 시퀀스 데이터 분리 \n",
    "def split_sequence(sequence, step): \n",
    "    x, y = list(), list() \n",
    "    \n",
    "    for i in range(len(sequence)): \n",
    "        end_idx = i + step \n",
    "        if end_idx > len(sequence) - 1:\n",
    "            break \n",
    "        \n",
    "        seq_x, seq_y = sequence[i:end_idx], sequence[end_idx] \n",
    "        x.append(seq_x) \n",
    "        y.append(seq_y) \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# sin 함수 학습 데이터 \n",
    "# -10 에서 10 사이 x축 범위를 가지는 sin() 함수 값을 0.1 단위로 증가 시켜 train_y 리스트에 저장.\n",
    "# train_y 리스트는 RNN 모델 학습에 필요한 학습 데이터 셋 \n",
    "x = [i for i in np.arange(start=-10, stop=10, step=0.1)]\n",
    "train_y = [np.sin(i) for i in x] \n",
    "\n",
    "# 하이퍼파라미터\n",
    "# RNN모델 사용하는 입력 시퀀스 길이(n_estimators) 15정의. n_estimators 만큼 RNN 메모리 쉘이 생성.\n",
    "# 입력 벡터 차원 크기 n_features 는 1 \n",
    "n_timesteps = 15\n",
    "n_features = 1\n",
    "\n",
    "# 시퀀스 나누기 \n",
    "# train_x.shape => (samples, timesteps) \n",
    "# train_y.shape => (samples) \n",
    "# RNN모델 입력 시퀀스를 만들기 위해 split_sequence() 함수 호출\n",
    "# sin파형의 학습 데이터가 들어 있는 train_y 리스트에서 n_timesteps 만큰 나눠서 입력 시퀀스를 생성 \n",
    "# split_sequence() 함수 내부 - 입력인자 넘어온 리스트 데이터를 순차적으로 step 크기 만큼 나눠 RNN 모델 사용될 입력 시퀀스(x) 와 출력값(y) 넘파이 배열로 만듦\n",
    "train_x, train_y = split_sequence(train_y, step=n_timesteps) \n",
    "print(\"shape x:{} / y: {}\".format(train_x.shape, train_y.shape)) \n",
    "\n",
    "# RNN 입력 벡터 크기를 맞추기 위해 벡터 차원 크기 변경 \n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features] \n",
    "# 케라스에서 RNN 계층 사용하려면 3차원 텐서 형태여야함. \n",
    "# 2차원인 (samples, time step) 인 train_x 를 RNN 모델의 입력 데이터 형상에 맞게 3차원(batch_size, time step, input length) 형태로 변환\n",
    "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features)\n",
    "print(\"train_x.shape = {}\".format(train_x.shape))\n",
    "print(\"train_y.shape = {}\".format(train_y.shape))\n",
    "\n",
    "# RNN 모델 정의 \n",
    "# sin 파형 데이터셋을 학습하기 위한 RNN계층 정의한 후 모델을 생성\n",
    "# SimpleRNN 계층 1개와 출력 위한 Dense 계층 1개 구성\n",
    "# SimpleRNN(units=RNN계층 전체 뉴런 수, return_sequence=RNN은닉상탯값 출력 여부 결정, False=마지막 시점 메모리 셀에서만 결과 출력, input_shape=모델 입력 데이터 형상)\n",
    "model = Sequential() \n",
    "model.add(SimpleRNN(units=10,\n",
    "                    return_sequences=False,\n",
    "                    input_shape=(n_timesteps,n_features)))\n",
    "model.add(Dense(1)) \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# 모델 학습 \n",
    "# 케라스 fit() 함수 이용 학습.\n",
    "# fit(데이터셋, 에포크값) \n",
    "# 오버피팅 방지 EarlyStopping 콜백 객체 사용 (patience=5 성능 개선 없을시  5만 더 학습)\n",
    "np.random.seed(0) \n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    mode='auto'\n",
    ")\n",
    "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping]) \n",
    "\n",
    "# loss 그래프 생성\n",
    "plt.plot(history.history['loss'], label='loss') \n",
    "plt.legend(loc='upper right') \n",
    "plt.show() \n",
    "\n",
    "# 테스트 데이터셋 생성 \n",
    "# 학습된 RNN모델 테스트 위해 \n",
    "# 10 ~ 20 사이 x축 범위 가지는 cos() 함수 값을 0.1 단위 증가시켜 calc_y 리스트에 저장 \n",
    "# calc_y 리스트에는 RNN 모델 테스트 하기 위한 전체 시퀀스 값이 저장\n",
    "# cos() 함수 이용해 테스트용 데이터셋을 만드는 이유 = 학습된 sin 파형과 주기적 차이를 주기 위해 \n",
    "test_x = np.arange(10, 20, 0.1) \n",
    "calc_y = np.cos(test_x)   # 테스트 정답 데이터 \n",
    "\n",
    "\n",
    "# RNN 모델 예측 및 로그 저장\n",
    "# 학습된 RNN 모델 예측값 그래프로 그리기 위해 test_y 리스트에 순차적 저장 \n",
    "test_y = calc_y[:n_timesteps] \n",
    "for i in range(len(test_x) - n_timesteps): \n",
    "    net_input = test_y[i : i + n_timesteps] \n",
    "    net_input = net_input.reshape((1, n_timesteps, n_features)) \n",
    "    train_y = model.predict(net_input, verbose=0) \n",
    "    print(test_y.shape, train_y.shape, i, i+n_timesteps) \n",
    "    test_y = np.append(test_y, train_y) \n",
    "    \n",
    "# 예측 결과 그래프 그리기 \n",
    "plt.plot(test_x, calc_y, label='ground truth', color='orange') \n",
    "plt.plot(test_x, test_y, label='predictions', color = 'blue') \n",
    "plt. legend(loc='upper left') \n",
    "plt.ylim(-2, 2) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 LSTM\n",
    "\n",
    "- RNN모델은 입력 시퀀스 시점(time step) 길어질수록 앞쪽 데이터가 뒤쪽으로 잘 전달 되지 않아 학습 능력 떨어짐 \n",
    "- RNN 다층 구조로 쌓으면 입력과 출력 데이터 사이 연관 관계가 줄어들어 장기 의존성 문제가 생김\n",
    "- 위 문제 보완하기 위해 기존 RNN 을 변형해 LSTM 개발\n",
    "\n",
    "- LSTM 내부구조\n",
    "    - 기본적인 RNN 은닉상태 계산 방식에 변화 은닉상탯값 이외 셀 상탯값 추가\n",
    "    - 은닉상탯값과 셀 상탯값을 계산하기 위한 3개 게이트 추가 (입력, 삭제, 출력) \n",
    "        - 입력게이트(input gate):현재 정보를 얼마나 기억할지 결정 \n",
    "        - 삭제게이트(forget gate): 이전 시점 셀 상탯값을 삭제하기 위해 사용\n",
    "            - 입력 게이트와 삭제 게이트 결괎값으로 현재 시점 셀 상태 계산\n",
    "        - 출력게이트(output gate): 현재 시점 은닉 상태 결정하는데 사용\n",
    "\n",
    "- 특정 범위만큼 sin 파형 시퀀스 학습해 다음 스텝의 파형 예측하는 LSTM 모델 구현         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape x:(185, 15) / y:(185,)\n",
      "train_x.shape = (185, 15, 1)\n",
      "train_y.shape = (185, 15, 1)\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 10s 11ms/step - loss: 0.5046\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4632\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4237\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3889\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3565\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3264\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2987\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2774\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2570\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2401\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2257\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2116\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1983\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1850\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1727\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1596\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1465\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1331\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1197\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1066\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0936\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0803\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0678\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0562\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0454\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0365\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0291\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0231\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0134\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0120\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0108\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0099\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0090\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0084\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0078\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0073\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0068\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0064\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0061\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0058\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0055\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0052\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0046\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0045\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0042\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0040\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0039\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0038\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0037\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0035\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0034\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0033\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0031\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0030\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0030\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0028\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0027\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0026\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0025\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0024\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0023\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0022\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0022\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0021\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0020\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0019\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0018\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0018\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0017\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0017\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0016\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0015\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0015\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0014\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0013\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0012\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0012\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0011\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0011\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0010\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0010\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 9.6784e-04\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.1195e-04\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.7622e-04\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8.4041e-04\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 8.0288e-04\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.7386e-04\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.3845e-04\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 7.1131e-04\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.8692e-04\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.5437e-04\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.3125e-04\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.0275e-04\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6918e-04\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.6684e-04\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.4259e-04\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.1252e-04\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.8612e-04\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.6496e-04\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.5988e-04\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.4071e-04\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.0593e-04\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.0143e-04\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.8322e-04\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5968e-04\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.5124e-04\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.3653e-04\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.2662e-04\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.1082e-04\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9695e-04\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.8760e-04\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.7466e-04\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.6706e-04\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.5694e-04\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.4685e-04\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.3963e-04\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2836e-04\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.2144e-04\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.1358e-04\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.0635e-04\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.9778e-04\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.9313e-04\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8570e-04\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.8017e-04\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8124e-04\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7160e-04\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.6046e-04\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5980e-04\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.4869e-04\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.4418e-04\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.4266e-04\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3297e-04\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.2940e-04\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.2759e-04\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2307e-04\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1957e-04\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.1673e-04\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1077e-04\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.0770e-04\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0543e-04\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0019e-04\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 9.9737e-05\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 9.4529e-05\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 9.5119e-05\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 9.2885e-05\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.6863e-05\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.0094e-05\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8.8074e-05\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8.0513e-05\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.1820e-05\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 7.9046e-05\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 7.3434e-05\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.3686e-05\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1998e-05\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.8742e-05\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.8625e-05\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.6122e-05\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 6.4196e-05\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6.5043e-05\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6.2292e-05\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.2630e-05\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6.0758e-05\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.8760e-05\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.7909e-05\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5.6958e-05\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.8014e-05\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.6041e-05\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5.2587e-05\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.2531e-05\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.1201e-05\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5.0252e-05\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.9131e-05\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.9023e-05\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.7677e-05\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.8683e-05\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.7892e-05\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.6154e-05\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.5266e-05\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.5250e-05\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.4838e-05\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.6027e-05\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.1897e-05\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.2967e-05\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.1450e-05\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.0735e-05\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.0517e-05\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.9996e-05\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.9657e-05\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.8063e-05\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.9064e-05\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.9206e-05\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8049e-05\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.7620e-05\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.7126e-05\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.6456e-05\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.5484e-05\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.5192e-05\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.4889e-05\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.4735e-05\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.3927e-05\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.4168e-05\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.4861e-05\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.3718e-05\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.3081e-05\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.3779e-05\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.2924e-05\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.3987e-05\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.2134e-05\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1685e-05\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3.1896e-05\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.1611e-05\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0136e-05\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0994e-05\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.0464e-05\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.1091e-05\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.0283e-05\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.1472e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,) (1, 1) 0 15\n",
      "(16,) (1, 1) 1 16\n",
      "(17,) (1, 1) 2 17\n",
      "(18,) (1, 1) 3 18\n",
      "(19,) (1, 1) 4 19\n",
      "(20,) (1, 1) 5 20\n",
      "(21,) (1, 1) 6 21\n",
      "(22,) (1, 1) 7 22\n",
      "(23,) (1, 1) 8 23\n",
      "(24,) (1, 1) 9 24\n",
      "(25,) (1, 1) 10 25\n",
      "(26,) (1, 1) 11 26\n",
      "(27,) (1, 1) 12 27\n",
      "(28,) (1, 1) 13 28\n",
      "(29,) (1, 1) 14 29\n",
      "(30,) (1, 1) 15 30\n",
      "(31,) (1, 1) 16 31\n",
      "(32,) (1, 1) 17 32\n",
      "(33,) (1, 1) 18 33\n",
      "(34,) (1, 1) 19 34\n",
      "(35,) (1, 1) 20 35\n",
      "(36,) (1, 1) 21 36\n",
      "(37,) (1, 1) 22 37\n",
      "(38,) (1, 1) 23 38\n",
      "(39,) (1, 1) 24 39\n",
      "(40,) (1, 1) 25 40\n",
      "(41,) (1, 1) 26 41\n",
      "(42,) (1, 1) 27 42\n",
      "(43,) (1, 1) 28 43\n",
      "(44,) (1, 1) 29 44\n",
      "(45,) (1, 1) 30 45\n",
      "(46,) (1, 1) 31 46\n",
      "(47,) (1, 1) 32 47\n",
      "(48,) (1, 1) 33 48\n",
      "(49,) (1, 1) 34 49\n",
      "(50,) (1, 1) 35 50\n",
      "(51,) (1, 1) 36 51\n",
      "(52,) (1, 1) 37 52\n",
      "(53,) (1, 1) 38 53\n",
      "(54,) (1, 1) 39 54\n",
      "(55,) (1, 1) 40 55\n",
      "(56,) (1, 1) 41 56\n",
      "(57,) (1, 1) 42 57\n",
      "(58,) (1, 1) 43 58\n",
      "(59,) (1, 1) 44 59\n",
      "(60,) (1, 1) 45 60\n",
      "(61,) (1, 1) 46 61\n",
      "(62,) (1, 1) 47 62\n",
      "(63,) (1, 1) 48 63\n",
      "(64,) (1, 1) 49 64\n",
      "(65,) (1, 1) 50 65\n",
      "(66,) (1, 1) 51 66\n",
      "(67,) (1, 1) 52 67\n",
      "(68,) (1, 1) 53 68\n",
      "(69,) (1, 1) 54 69\n",
      "(70,) (1, 1) 55 70\n",
      "(71,) (1, 1) 56 71\n",
      "(72,) (1, 1) 57 72\n",
      "(73,) (1, 1) 58 73\n",
      "(74,) (1, 1) 59 74\n",
      "(75,) (1, 1) 60 75\n",
      "(76,) (1, 1) 61 76\n",
      "(77,) (1, 1) 62 77\n",
      "(78,) (1, 1) 63 78\n",
      "(79,) (1, 1) 64 79\n",
      "(80,) (1, 1) 65 80\n",
      "(81,) (1, 1) 66 81\n",
      "(82,) (1, 1) 67 82\n",
      "(83,) (1, 1) 68 83\n",
      "(84,) (1, 1) 69 84\n",
      "(85,) (1, 1) 70 85\n",
      "(86,) (1, 1) 71 86\n",
      "(87,) (1, 1) 72 87\n",
      "(88,) (1, 1) 73 88\n",
      "(89,) (1, 1) 74 89\n",
      "(90,) (1, 1) 75 90\n",
      "(91,) (1, 1) 76 91\n",
      "(92,) (1, 1) 77 92\n",
      "(93,) (1, 1) 78 93\n",
      "(94,) (1, 1) 79 94\n",
      "(95,) (1, 1) 80 95\n",
      "(96,) (1, 1) 81 96\n",
      "(97,) (1, 1) 82 97\n",
      "(98,) (1, 1) 83 98\n",
      "(99,) (1, 1) 84 99\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sin 곡선 예측 LSTM 모델 사용 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM \n",
    "\n",
    "# time step 만큼 시퀀스 데이터 분리 \n",
    "def split_sequence(sequence, step):\n",
    "    x, y = list(), list() \n",
    "    \n",
    "    for i in range(len(sequence)): \n",
    "        end_idx = i + step \n",
    "        if end_idx > len(sequence) - 1: \n",
    "            break \n",
    "        \n",
    "        seq_x, seq_y = sequence[i:end_idx], sequence[end_idx] \n",
    "        x.append(seq_x) \n",
    "        y.append(seq_y) \n",
    "        \n",
    "    return np.array(x), np.array(y) \n",
    "    \n",
    "# sin함수 학습 데이터 \n",
    "# -10에서 10 사이 x축 범위 가지는 sin() 함수 값을 0.1 단위로 증가시켜 train_y 리스트에 저장 \n",
    "# train_y 는 RNN 모델 학습에 필요한 학습 데이터셋\n",
    "x = [i for i in np.arange(start=-10, stop=10, step=0.1)] \n",
    "train_y = [np.sin(i) for i in x] \n",
    "\n",
    "# 하이퍼파라미터 \n",
    "# LSTM 모델에서 사용하는 입력 시퀀스 길이(n_timesteps) 15 , 입력 벡터 차원 크기 n_features 1 \n",
    "n_timesteps = 15 \n",
    "n_features = 1 \n",
    "\n",
    "# 시퀀스 나누기 \n",
    "# train_x.sahpe => (samples, timesteps) \n",
    "# train_y.shape => (samples) \n",
    "# LSTM 모델 입력 시퀀스 만들기 위해 split_sequence() 함수 호출\n",
    "# sin 파형 학습 데이터 들어 있는 train_y 리스트에서 n_timesteps 만큰 나눠서 입력 시퀀스 생성 \n",
    "train_x, train_y = split_sequence(train_y, step=n_timesteps) \n",
    "print('shape x:{} / y:{}'.format(train_x.shape, train_y.shape)) \n",
    "\n",
    "# LSTM 입력 벡터 크기를 맞추기 위해 벡터 차원 크기 변경 \n",
    "# resahpe from [samples, timesteps] into [samples, timesteps, features] \n",
    "# 케라스 에서 LSTM 계층 사용하기 위해 3차원 텐서 형태여야 함\n",
    "# 따라서 현재 2차원(samples, time step) 인 train_x 를 LSTM 모델 입력 데이터 형상에 맞게 3차원 (batch size, time step, input length) 형태로 변환\n",
    "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features) \n",
    "print('train_x.shape = {}'.format(train_x.shape)) \n",
    "print('train_y.shape = {}'.format(train_y.shape)) \n",
    "\n",
    "# LSTM 모델 정의 \n",
    "# sin 파형 데이터셋을 학습하기 위한 LSTM 계층을 정의한 후 모델을 생성\n",
    "# LSTM 계층 1개와 출력 위한 Dense 계층 1개롤 구성\n",
    "# LSTM 모델 출력값과 실제 정답의 오차를 계산하는 손실함수 = mse , 옵타마이자 = adam \n",
    "model = Sequential() \n",
    "model.add(LSTM(units=10,\n",
    "               return_sequences=False, \n",
    "               input_shape=(n_timesteps, n_features))) \n",
    "model.add(Dense(1)) \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# 모델 학습 \n",
    "np.random.seed(0) \n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    mode='auto'\n",
    ")\n",
    "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping])\n",
    "\n",
    "# loss 그래프 생성 \n",
    "plt.plot(history.history['loss'], label = 'loss') \n",
    "plt.legend(loc='upper right') \n",
    "plt.show() \n",
    "\n",
    "# 테스트 데이터셋 생성 \n",
    "test_x = np.arange(10, 20, 0.1) \n",
    "calc_y = np.cos(test_x)   # 테스트 정답 데이터 \n",
    "\n",
    "# LSTM 모델 예측 및 로그 저장 \n",
    "test_y = calc_y[:n_timesteps] \n",
    "for i in range(len(test_x) - n_timesteps):\n",
    "    net_input = test_y[i : i + n_timesteps] \n",
    "    net_input = net_input.reshape((1, n_timesteps, n_features)) \n",
    "    train_y = model.predict(net_input, verbose=0) \n",
    "    print(test_y.shape, train_y.shape, i, i + n_timesteps) \n",
    "    test_y = np.append(test_y, train_y) \n",
    "    \n",
    "# 예측 결과 그래프 그리기 \n",
    "plt.plot(test_x, calc_y, label = 'ground truth', color = 'orange') \n",
    "plt.plot(test_x, test_y, label = 'predictions', color = 'blue') \n",
    "plt.legend(loc='upper left') \n",
    "plt.ylim(-2, 2) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 양방향 LSTM \n",
    "\n",
    "- RNN과 LSTM 은 일반 신경망과 다르게 시퀀스 또는 시계열 데이터 처리에 특화되어 은닉층 에서 과거 정보를 기억할 수 있다\n",
    "- 그러나 순환 신경망 구조적 특성상 데이터가 입력 순으로 처리되기 때무에 이전 시점 정보만 활용할 수 밖에 없는 단점\n",
    "- 문장 길어질수록 성능이 저하\n",
    "- 자연어 처리에서 입력 데이터 정방향 처리만큼 역방향 처리도 중요.\n",
    "- 양방향 LSTM(Bidirectional LSTM) : 기존 LSTM 계층에 역방향 처리하는 LSTM 계층을 하나 더 추가해 양방향에서 문장 패턴 분석할 수있도록 구성\n",
    "    - 입력 문장을 양방향 처리하므로 시퀀스 길이가 길어진다 해도 정보 손실 없이 처리 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 15s - loss: 0.6773 - accuracy: 0.7500 - 15s/epoch - 15s/step\n",
      "1/1 - 0s - loss: 0.7095 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.6792 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.7183 - accuracy: 0.0000e+00 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.6827 - accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.6734 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.7198 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.6859 - accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.7043 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.6651 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6742 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.6729 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.7130 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6994 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6963 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6861 - accuracy: 0.5000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.7308 - accuracy: 0.0000e+00 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.7082 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.7215 - accuracy: 0.2500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6731 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.7188 - accuracy: 0.2500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6546 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6610 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6825 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6590 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6897 - accuracy: 0.5000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6543 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6934 - accuracy: 0.5000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.6717 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.6901 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6917 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6622 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6328 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.7341 - accuracy: 0.0000e+00 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6882 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6398 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6853 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6436 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6593 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6747 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6633 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.6146 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6430 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6344 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6630 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6402 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6237 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6130 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.6978 - accuracy: 0.2500 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.7007 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.6954 - accuracy: 0.2500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.7425 - accuracy: 0.0000e+00 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6467 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6666 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6242 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6113 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.6296 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6058 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6903 - accuracy: 0.5000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6922 - accuracy: 0.2500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6064 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6067 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6774 - accuracy: 0.5000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.6469 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5827 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.6230 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6268 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5929 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.5994 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5788 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.7421 - accuracy: 0.2500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.6008 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6784 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.5649 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.6241 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.5871 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5578 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5702 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5627 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5748 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.5670 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6055 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.5535 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.5950 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5636 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.5746 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5676 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5559 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.5525 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6276 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5242 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4903 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6540 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5592 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6643 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4990 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4635 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6173 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.5539 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5156 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6624 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5269 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6233 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.6069 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.4333 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.4637 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.5434 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.4800 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.4997 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.4298 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.8115 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6730 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4335 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4743 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.4287 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6130 - accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.4682 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4481 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4234 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.4272 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.4352 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4501 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4781 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4071 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.3993 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.4485 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3935 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.3811 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3954 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "1/1 - 0s - loss: 0.3450 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4168 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4397 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.3945 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3226 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3334 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3205 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3572 - accuracy: 1.0000 - 33ms/epoch - 33ms/step\n",
      "1/1 - 0s - loss: 0.2983 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3442 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.3229 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3127 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.4110 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3112 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2802 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 1.2627 - accuracy: 0.2500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3426 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3161 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.7558 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2991 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2884 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.3021 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3990 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3148 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.2967 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3205 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6012 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5844 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.5243 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3018 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3244 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2838 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2420 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2911 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2070 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2964 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3480 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3013 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.4805 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3174 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2887 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2221 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.2357 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.4681 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3086 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2676 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3419 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2633 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2918 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4003 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2943 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2893 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2398 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1689 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2194 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2047 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2337 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2997 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2125 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2449 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2422 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1877 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2630 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2115 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2922 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2564 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2355 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2133 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1886 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1947 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2437 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2105 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.3172 - accuracy: 0.7500 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.5612 - accuracy: 0.7500 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.5019 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1913 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2312 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2699 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2220 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1941 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1617 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1747 - accuracy: 1.0000 - 65ms/epoch - 65ms/step\n",
      "1/1 - 0s - loss: 0.2360 - accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.2497 - accuracy: 0.7500 - 38ms/epoch - 38ms/step\n",
      "1/1 - 0s - loss: 0.2630 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1745 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.1824 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2228 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2660 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4951 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2933 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.1296 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1675 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 1.6373 - accuracy: 0.2500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2145 - accuracy: 1.0000 - 105ms/epoch - 105ms/step\n",
      "1/1 - 0s - loss: 0.2097 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2882 - accuracy: 0.7500 - 43ms/epoch - 43ms/step\n",
      "1/1 - 0s - loss: 0.2734 - accuracy: 0.7500 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 1.0889 - accuracy: 0.5000 - 28ms/epoch - 28ms/step\n",
      "1/1 - 0s - loss: 0.3783 - accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.2121 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1926 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1721 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2395 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2299 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1403 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2084 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2875 - accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.4605 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 1.4463 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4222 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1861 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2303 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2774 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1841 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2445 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3251 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5093 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2642 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2681 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3680 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.4947 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1260 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3154 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1693 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1398 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1370 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1453 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2317 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.4749 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1521 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1702 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2593 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.4802 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1825 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1259 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.2184 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3099 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1212 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1228 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2127 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1238 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1556 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.3866 - accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.1120 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
      "1/1 - 0s - loss: 0.1934 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1150 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2092 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1317 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1375 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2447 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2559 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1796 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1956 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.2061 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2073 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2890 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2627 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 1.4936 - accuracy: 0.5000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.0998 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1686 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2936 - accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.1890 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4166 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1244 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2878 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1624 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 1.1144 - accuracy: 0.5000 - 5ms/epoch - 5ms/step\n",
      "1/1 - 0s - loss: 0.1522 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3643 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1987 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5111 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2623 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2315 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1674 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2188 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 1.1084 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1586 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1869 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3623 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2283 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1642 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2417 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1226 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4446 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2766 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1662 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2954 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2274 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1801 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2060 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1099 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.2492 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1411 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2479 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1763 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1113 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2511 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1280 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.7791 - accuracy: 0.5000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2558 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1420 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2320 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1989 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1975 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.1574 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1894 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1623 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1468 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1552 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5558 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2032 - accuracy: 1.0000 - 75ms/epoch - 75ms/step\n",
      "1/1 - 0s - loss: 0.6666 - accuracy: 0.7500 - 46ms/epoch - 46ms/step\n",
      "1/1 - 0s - loss: 0.1504 - accuracy: 1.0000 - 83ms/epoch - 83ms/step\n",
      "1/1 - 0s - loss: 0.1941 - accuracy: 0.7500 - 24ms/epoch - 24ms/step\n",
      "1/1 - 0s - loss: 0.2485 - accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.2148 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1713 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1627 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2007 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6361 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1539 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2085 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1355 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1339 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1754 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1217 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2261 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1610 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1622 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1692 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1535 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.7020 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1634 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1297 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1900 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.9438 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2833 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5803 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 1.4341 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1538 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.2759 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2417 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1327 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.2246 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3205 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1634 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2908 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1377 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2100 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1736 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1381 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2473 - accuracy: 0.7500 - 5ms/epoch - 5ms/step\n",
      "1/1 - 0s - loss: 1.4139 - accuracy: 0.2500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1605 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1720 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2060 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.1213 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1962 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.5600 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1821 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1505 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1244 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1496 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 1.1274 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5212 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1233 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1137 - accuracy: 1.0000 - 40ms/epoch - 40ms/step\n",
      "1/1 - 0s - loss: 0.1555 - accuracy: 1.0000 - 30ms/epoch - 30ms/step\n",
      "1/1 - 0s - loss: 0.1081 - accuracy: 1.0000 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 0.2022 - accuracy: 0.7500 - 40ms/epoch - 40ms/step\n",
      "1/1 - 0s - loss: 0.2646 - accuracy: 0.7500 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 1.1649 - accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.1811 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.4406 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2327 - accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.3260 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.5000 - accuracy: 0.7500 - 39ms/epoch - 39ms/step\n",
      "1/1 - 0s - loss: 0.1160 - accuracy: 1.0000 - 72ms/epoch - 72ms/step\n",
      "1/1 - 0s - loss: 0.2108 - accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.1672 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.1547 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1372 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1198 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.2116 - accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.1270 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1409 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.4985 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1292 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.2055 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.2644 - accuracy: 0.7500 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.2052 - accuracy: 0.7500 - 68ms/epoch - 68ms/step\n",
      "1/1 - 0s - loss: 0.3025 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.9442 - accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1318 - accuracy: 1.0000 - 33ms/epoch - 33ms/step\n",
      "1/1 - 0s - loss: 0.2540 - accuracy: 0.7500 - 45ms/epoch - 45ms/step\n",
      "1/1 - 0s - loss: 0.1584 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
      "1/1 - 0s - loss: 0.1569 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
      "1/1 - 0s - loss: 0.1500 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4731 - accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.4977 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.4933 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.2337 - accuracy: 1.0000 - 34ms/epoch - 34ms/step\n",
      "1/1 - 0s - loss: 0.4447 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1917 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
      "1/1 - 0s - loss: 0.1460 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1657 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1418 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.1567 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2184 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1337 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3723 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3296 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1665 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2083 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
      "1/1 - 0s - loss: 0.2030 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1902 - accuracy: 1.0000 - 75ms/epoch - 75ms/step\n",
      "1/1 - 0s - loss: 0.2612 - accuracy: 0.7500 - 30ms/epoch - 30ms/step\n",
      "1/1 - 0s - loss: 0.3043 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1622 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1262 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.4452 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1186 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1254 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.1424 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2187 - accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.2143 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1691 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2099 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1886 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1258 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1309 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1622 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1153 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1869 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1594 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.4162 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1567 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4011 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1924 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2377 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1801 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.2066 - accuracy: 1.0000 - 49ms/epoch - 49ms/step\n",
      "1/1 - 0s - loss: 0.2027 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1264 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.1855 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.4617 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1756 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1688 - accuracy: 1.0000 - 41ms/epoch - 41ms/step\n",
      "1/1 - 0s - loss: 0.2255 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2014 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2140 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1282 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2119 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.1945 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.0971 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1696 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.8365 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1207 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1896 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1897 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1101 - accuracy: 1.0000 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 0.1464 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 0.1599 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
      "1/1 - 0s - loss: 0.2002 - accuracy: 1.0000 - 43ms/epoch - 43ms/step\n",
      "1/1 - 0s - loss: 0.1665 - accuracy: 1.0000 - 41ms/epoch - 41ms/step\n",
      "1/1 - 0s - loss: 0.4858 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2361 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1148 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2560 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.0926 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1667 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1570 - accuracy: 1.0000 - 33ms/epoch - 33ms/step\n",
      "1/1 - 0s - loss: 0.1310 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1618 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1598 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 1.1521 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1475 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2076 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.1222 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1394 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1356 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 1.1801 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.6696 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1546 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1546 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.4953 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1398 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1094 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
      "1/1 - 0s - loss: 0.2865 - accuracy: 0.7500 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 0.5515 - accuracy: 0.7500 - 30ms/epoch - 30ms/step\n",
      "1/1 - 0s - loss: 0.2414 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1725 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1608 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1151 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2277 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2163 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1465 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1586 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.0952 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1637 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3122 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1373 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2187 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1569 - accuracy: 1.0000 - 45ms/epoch - 45ms/step\n",
      "1/1 - 0s - loss: 0.2205 - accuracy: 0.7500 - 34ms/epoch - 34ms/step\n",
      "1/1 - 0s - loss: 0.2228 - accuracy: 1.0000 - 34ms/epoch - 34ms/step\n",
      "1/1 - 0s - loss: 0.2162 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2048 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2161 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.0923 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "1/1 - 0s - loss: 0.1220 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.0886 - accuracy: 1.0000 - 43ms/epoch - 43ms/step\n",
      "1/1 - 0s - loss: 0.1572 - accuracy: 1.0000 - 30ms/epoch - 30ms/step\n",
      "1/1 - 0s - loss: 1.0741 - accuracy: 0.5000 - 29ms/epoch - 29ms/step\n",
      "1/1 - 0s - loss: 0.1056 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3128 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1535 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2227 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.2064 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2011 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1179 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1911 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2459 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1969 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1296 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1369 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.1854 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1347 - accuracy: 1.0000 - 53ms/epoch - 53ms/step\n",
      "1/1 - 0s - loss: 0.4443 - accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 1.0061 - accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1912 - accuracy: 1.0000 - 33ms/epoch - 33ms/step\n",
      "1/1 - 0s - loss: 0.1349 - accuracy: 1.0000 - 48ms/epoch - 48ms/step\n",
      "1/1 - 0s - loss: 0.1760 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.1690 - accuracy: 1.0000 - 40ms/epoch - 40ms/step\n",
      "1/1 - 0s - loss: 0.2255 - accuracy: 0.7500 - 40ms/epoch - 40ms/step\n",
      "1/1 - 0s - loss: 0.2298 - accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.1842 - accuracy: 1.0000 - 37ms/epoch - 37ms/step\n",
      "1/1 - 0s - loss: 0.2498 - accuracy: 0.7500 - 51ms/epoch - 51ms/step\n",
      "1/1 - 0s - loss: 0.1227 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.4037 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2605 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1884 - accuracy: 0.7500 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1969 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1392 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.8879 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5936 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1451 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.2215 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1295 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.2324 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1976 - accuracy: 1.0000 - 42ms/epoch - 42ms/step\n",
      "1/1 - 0s - loss: 0.1448 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.1114 - accuracy: 1.0000 - 49ms/epoch - 49ms/step\n",
      "1/1 - 0s - loss: 0.1181 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1755 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.0811 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5484 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1109 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.4482 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1221 - accuracy: 1.0000 - 40ms/epoch - 40ms/step\n",
      "1/1 - 0s - loss: 0.0819 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1625 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1840 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1229 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1961 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.4448 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2179 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1646 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1803 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2167 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2356 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1154 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1504 - accuracy: 1.0000 - 42ms/epoch - 42ms/step\n",
      "1/1 - 0s - loss: 0.1010 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2320 - accuracy: 0.7500 - 37ms/epoch - 37ms/step\n",
      "1/1 - 0s - loss: 0.1380 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2085 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 0.1394 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1991 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.0928 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1800 - accuracy: 1.0000 - 67ms/epoch - 67ms/step\n",
      "1/1 - 0s - loss: 0.1363 - accuracy: 1.0000 - 38ms/epoch - 38ms/step\n",
      "1/1 - 0s - loss: 0.1795 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.1050 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1426 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.6380 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5461 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5170 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1542 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
      "1/1 - 0s - loss: 0.5366 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1308 - accuracy: 1.0000 - 45ms/epoch - 45ms/step\n",
      "1/1 - 0s - loss: 0.1755 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.1196 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.0868 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1587 - accuracy: 1.0000 - 37ms/epoch - 37ms/step\n",
      "1/1 - 0s - loss: 0.1952 - accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.4174 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1200 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.8628 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1010 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1431 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1577 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1640 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1511 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.2133 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1611 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1889 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1608 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1995 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1169 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.0756 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1988 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.0924 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1270 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1266 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1707 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1933 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2010 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1949 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2510 - accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.5393 - accuracy: 0.7500 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 0.2215 - accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.1554 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.6208 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2268 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1265 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4935 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2162 - accuracy: 0.7500 - 31ms/epoch - 31ms/step\n",
      "1/1 - 0s - loss: 0.2179 - accuracy: 0.7500 - 42ms/epoch - 42ms/step\n",
      "1/1 - 0s - loss: 0.1994 - accuracy: 0.7500 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 0.1720 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.4770 - accuracy: 0.7500 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 0.7601 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.3973 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1960 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1077 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1389 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0961 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.1355 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 0.1373 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.1768 - accuracy: 1.0000 - 59ms/epoch - 59ms/step\n",
      "1/1 - 0s - loss: 0.0812 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
      "1/1 - 0s - loss: 0.1182 - accuracy: 1.0000 - 43ms/epoch - 43ms/step\n",
      "1/1 - 0s - loss: 0.0892 - accuracy: 1.0000 - 69ms/epoch - 69ms/step\n",
      "1/1 - 0s - loss: 0.1060 - accuracy: 1.0000 - 37ms/epoch - 37ms/step\n",
      "1/1 - 0s - loss: 0.1891 - accuracy: 1.0000 - 84ms/epoch - 84ms/step\n",
      "1/1 - 0s - loss: 0.0992 - accuracy: 1.0000 - 161ms/epoch - 161ms/step\n",
      "1/1 - 0s - loss: 0.1348 - accuracy: 1.0000 - 132ms/epoch - 132ms/step\n",
      "1/1 - 0s - loss: 0.4287 - accuracy: 0.7500 - 227ms/epoch - 227ms/step\n",
      "1/1 - 0s - loss: 0.1255 - accuracy: 1.0000 - 286ms/epoch - 286ms/step\n",
      "1/1 - 0s - loss: 0.0957 - accuracy: 1.0000 - 130ms/epoch - 130ms/step\n",
      "1/1 - 0s - loss: 0.1785 - accuracy: 1.0000 - 142ms/epoch - 142ms/step\n",
      "1/1 - 0s - loss: 0.3382 - accuracy: 0.7500 - 33ms/epoch - 33ms/step\n",
      "1/1 - 0s - loss: 0.1038 - accuracy: 1.0000 - 58ms/epoch - 58ms/step\n",
      "1/1 - 0s - loss: 0.0790 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1363 - accuracy: 1.0000 - 63ms/epoch - 63ms/step\n",
      "1/1 - 0s - loss: 0.0840 - accuracy: 1.0000 - 79ms/epoch - 79ms/step\n",
      "1/1 - 0s - loss: 0.2958 - accuracy: 0.7500 - 35ms/epoch - 35ms/step\n",
      "1/1 - 0s - loss: 0.0952 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 0.2171 - accuracy: 0.7500 - 47ms/epoch - 47ms/step\n",
      "1/1 - 0s - loss: 0.1684 - accuracy: 1.0000 - 39ms/epoch - 39ms/step\n",
      "1/1 - 0s - loss: 0.0851 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.0996 - accuracy: 1.0000 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 0.1226 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1453 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.0655 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1006 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.2185 - accuracy: 0.7500 - 40ms/epoch - 40ms/step\n",
      "1/1 - 0s - loss: 0.3159 - accuracy: 0.7500 - 35ms/epoch - 35ms/step\n",
      "1/1 - 0s - loss: 0.6593 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.2192 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1415 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.8627 - accuracy: 0.5000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.0810 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.1023 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.0886 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.3727 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1862 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0890 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.2804 - accuracy: 0.7500 - 24ms/epoch - 24ms/step\n",
      "1/1 - 0s - loss: 0.2517 - accuracy: 0.7500 - 106ms/epoch - 106ms/step\n",
      "1/1 - 0s - loss: 0.1018 - accuracy: 1.0000 - 47ms/epoch - 47ms/step\n",
      "1/1 - 0s - loss: 0.1403 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.1976 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1496 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2015 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.0740 - accuracy: 1.0000 - 80ms/epoch - 80ms/step\n",
      "1/1 - 0s - loss: 0.5334 - accuracy: 0.7500 - 62ms/epoch - 62ms/step\n",
      "1/1 - 0s - loss: 0.2078 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
      "1/1 - 0s - loss: 0.0962 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.9567 - accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.5536 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.2490 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2065 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1842 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.2213 - accuracy: 0.7500 - 29ms/epoch - 29ms/step\n",
      "1/1 - 0s - loss: 0.1627 - accuracy: 1.0000 - 47ms/epoch - 47ms/step\n",
      "1/1 - 0s - loss: 0.5522 - accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1636 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.6900 - accuracy: 0.7500 - 25ms/epoch - 25ms/step\n",
      "1/1 - 0s - loss: 0.0790 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
      "1/1 - 0s - loss: 0.0797 - accuracy: 1.0000 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 0.1476 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1890 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1073 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1283 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1366 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1740 - accuracy: 1.0000 - 88ms/epoch - 88ms/step\n",
      "1/1 - 0s - loss: 0.1385 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.1664 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.1355 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.1849 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.8539 - accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1688 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.2334 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1594 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1410 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4734 - accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.1247 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
      "1/1 - 0s - loss: 0.3965 - accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.0785 - accuracy: 1.0000 - 59ms/epoch - 59ms/step\n",
      "1/1 - 0s - loss: 0.1818 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2271 - accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.1669 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1122 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.2736 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.5785 - accuracy: 0.7500 - 32ms/epoch - 32ms/step\n",
      "1/1 - 0s - loss: 0.5432 - accuracy: 0.7500 - 54ms/epoch - 54ms/step\n",
      "1/1 - 0s - loss: 0.1378 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n",
      "1/1 - 0s - loss: 0.2298 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1337 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2618 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2150 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1411 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1370 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2018 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1817 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.0799 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1223 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1719 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2088 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.1837 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1619 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1120 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1502 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5218 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1372 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4675 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2379 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0865 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1869 - accuracy: 1.0000 - 33ms/epoch - 33ms/step\n",
      "1/1 - 0s - loss: 0.3902 - accuracy: 0.7500 - 41ms/epoch - 41ms/step\n",
      "1/1 - 0s - loss: 0.0571 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1627 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1027 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1058 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2492 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4231 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1449 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1812 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1601 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
      "1/1 - 0s - loss: 0.3513 - accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.0662 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1485 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2180 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0620 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1555 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2596 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.5597 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1596 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2097 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.0974 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1353 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1095 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4770 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.1165 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.0685 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1614 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.0558 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.5027 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.2172 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1669 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.0482 - accuracy: 1.0000 - 45ms/epoch - 45ms/step\n",
      "1/1 - 0s - loss: 0.1037 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.0886 - accuracy: 1.0000 - 39ms/epoch - 39ms/step\n",
      "1/1 - 0s - loss: 0.0859 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1105 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1381 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.4522 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.0580 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2249 - accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.0866 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.4023 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.6961 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1177 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1039 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.4727 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1247 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1561 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.4016 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1478 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
      "1/1 - 0s - loss: 0.0949 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1303 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1489 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1657 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1627 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
      "1/1 - 0s - loss: 0.1581 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1490 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.1424 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
      "1/1 - 0s - loss: 0.1450 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.3440 - accuracy: 0.7500 - 28ms/epoch - 28ms/step\n",
      "1/1 - 0s - loss: 0.4229 - accuracy: 0.7500 - 44ms/epoch - 44ms/step\n",
      "1/1 - 0s - loss: 0.0899 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.0797 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.4689 - accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.3577 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.7874 - accuracy: 0.5000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2265 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1846 - accuracy: 0.7500 - 36ms/epoch - 36ms/step\n",
      "1/1 - 0s - loss: 0.4519 - accuracy: 0.7500 - 29ms/epoch - 29ms/step\n",
      "1/1 - 0s - loss: 0.5934 - accuracy: 0.5000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.4533 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.0714 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.3671 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2359 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.4178 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1568 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1850 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1856 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1833 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1227 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.6716 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1166 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1560 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1935 - accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
      "1/1 - 0s - loss: 0.0664 - accuracy: 1.0000 - 49ms/epoch - 49ms/step\n",
      "1/1 - 0s - loss: 0.4472 - accuracy: 0.7500 - 39ms/epoch - 39ms/step\n",
      "1/1 - 0s - loss: 0.1889 - accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.5317 - accuracy: 0.7500 - 48ms/epoch - 48ms/step\n",
      "1/1 - 0s - loss: 0.1305 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1879 - accuracy: 1.0000 - 34ms/epoch - 34ms/step\n",
      "1/1 - 0s - loss: 0.2006 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2316 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1307 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
      "1/1 - 0s - loss: 0.1338 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1020 - accuracy: 1.0000 - 32ms/epoch - 32ms/step\n",
      "1/1 - 0s - loss: 0.1702 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
      "1/1 - 0s - loss: 0.2201 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
      "1/1 - 0s - loss: 0.0637 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1185 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1083 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1316 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1836 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1503 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1230 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2283 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2943 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.0891 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.0991 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1459 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1142 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1972 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.0448 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.5295 - accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.2247 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5588 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.0810 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5554 - accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2819 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1066 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1323 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3279 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1406 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.0791 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.5232 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2392 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2342 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0838 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.0738 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.0516 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2075 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.5052 - accuracy: 0.7500 - 37ms/epoch - 37ms/step\n",
      "1/1 - 0s - loss: 0.5113 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1363 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1667 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1877 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.0404 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1502 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1507 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1757 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
      "1/1 - 0s - loss: 0.1227 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1199 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1385 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.4137 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.5701 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1426 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1463 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2061 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.2268 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0608 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.5578 - accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.2238 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1210 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n",
      "1/1 - 0s - loss: 0.1459 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1123 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1123 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2636 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0438 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "1/1 - 0s - loss: 0.3848 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.4489 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1231 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3798 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "1/1 - 0s - loss: 0.0518 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.0541 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.1839 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6385 - accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3946 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.6876 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1527 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.5086 - accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.1177 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
      "1/1 - 0s - loss: 0.1240 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.1628 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2645 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1769 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0560 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1795 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.1820 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1806 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.6831 - accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
      "1/1 - 0s - loss: 0.2655 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1052 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1610 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1332 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.2641 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1200 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.3051 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0861 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1393 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.3936 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.0747 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.0607 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "1/1 - 0s - loss: 0.1361 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1005 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.2496 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1174 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1646 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2173 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "1/1 - 0s - loss: 0.1855 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.0796 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.1940 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.0766 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.0920 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.3149 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1292 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "1/1 - 0s - loss: 0.2576 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1007 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
      "1/1 - 0s - loss: 0.3276 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2028 - accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "1/1 - 0s - loss: 0.1519 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.4887 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "1/1 - 0s - loss: 0.1444 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "1/1 - 0s - loss: 0.0978 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.1640 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "1/1 - 0s - loss: 0.2071 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "1/1 - 0s - loss: 0.1987 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "1/1 - 0s - loss: 0.0966 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.1752 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "1/1 - 0s - loss: 0.4847 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "1/1 - 0s - loss: 0.0977 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "실젯값 : [0] 예측값 :  0\n",
      "실젯값 : [0] 예측값 :  0\n",
      "실젯값 : [0] 예측값 :  0\n",
      "실젯값 : [0] 예측값 :  0\n"
     ]
    }
   ],
   "source": [
    "# 양방향 LSTM \n",
    "import numpy as np\n",
    "from random import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, TimeDistributed\n",
    "\n",
    "# 시퀀스 생성 \n",
    "def get_sequence(n_timesteps):\n",
    "    # 0~1 사이의 랜덤 시퀀스 생성\n",
    "    X = np.array([random() for _ in range(n_timesteps)])\n",
    "\n",
    "    # 클래스 분류 기준\n",
    "    limit = n_timesteps / 4.0\n",
    "\n",
    "    # 누적합 시퀀스에서 클래스 결정\n",
    "    # 누적합 항목이 limit보다 작은 경우 0, 아닌 경우 1로 분류\n",
    "    y = np.array([0 if x < limit else 1 for x in np.cumsum(X)])\n",
    "\n",
    "    # LSTM 입력을 위해 3차원 텐서 형태로 변경\n",
    "    X = X.reshape(1, n_timesteps, 1)\n",
    "    y = y.reshape(1, n_timesteps, 1)\n",
    "    return X, y\n",
    "\n",
    "# 하이퍼 파라미터 \n",
    "n_units = 20\n",
    "n_timesteps = 4\n",
    "\n",
    "# 양방향 LSTM 모델 정의 \n",
    "# 양방향 설정 위해 Bidirectional 래퍼 사용 \n",
    "# 양방향 LSTM 정의할 때 주의할 점. = 정방향, 역방향 LSTM 계층에 모든 출력값을 연결해야 하기 때문에 return_sequences 인자를 반드시 True \n",
    "#   Dense 계층을 TimeDistributed 래퍼 사용해 3차원 텐서 입력 받을 수 있게 확장해야 함\n",
    "#   양방향 LSTM 모델은 0 또는 1 예측하는 이항 분류 모델. 따라서 마지막 Dense 계층 활성화 함수 시그모이드 함수 \n",
    "#   손실함수로 binary_crossentropy 사용\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(n_units, return_sequences=True, input_shape=(n_timesteps, 1))))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습 \n",
    "# epoch마다 학습 데이터를 생성해서 학습 \n",
    "# 학습 데이터 배치 사이즈에 맞게 생성해 fit() 메서드 한 번만 호출 하는 방법도 있지만 배치 사이즈 1로 설정해 에포크 횟수만큼 여러 번 호출 가능\n",
    "for epoch in range(1000):\n",
    "    X, y = get_sequence(n_timesteps)\n",
    "    model.fit(X, y, epochs=1, batch_size=1, verbose=2)\n",
    "    \n",
    "# 모델 평가 \n",
    "# 테스트 데이터 시퀀스를 생성한 후 예측값과 실젯값을 비교 \n",
    "# # 오류 발생\n",
    "# predicted = model.predict_classes(token_list, verbose=0)\n",
    "\n",
    "# # 오류 해결\n",
    "# y_prob = model.predict(token_list, verbose=0) \n",
    "# predicted = y_prob.argmax(axis=-1)\n",
    "\n",
    "X, y = get_sequence(n_timesteps)\n",
    "yhat = model.predict(X, verbose=0)\n",
    "predicted = yhat.argmax(axis=-1) \n",
    "for i in range(n_timesteps):\n",
    "    print('실젯값 :', y[0, i], '예측값 : ', predicted[0, i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4 개체명 인식 \n",
    "\n",
    "- 문장 내에 포함된 어떤 단어가 인물, 장소, 날짜 등을 의미하는 단어인지 인식하는 것 \n",
    "- 개체명 인식기 (NER = Named Entity Recognition) \n",
    "- 챗봇에서 문장을 정확하게 해석하기 위해 반드시 해야하는 전처리 과정 \n",
    "    - 예: 날짜와 지역에 대해 개체 인식 할 수 있는 개체명 인식 모델이 있다고 하면 챗봇은..\n",
    "    - '내일 부산 날씨 알려줘' - 입력문장\n",
    "    - 문장 의도 분류: 날씨 요청\n",
    "    - 개체명 인식 결과: 내일(날짜) / 부산(지역) \n",
    "\n",
    "- BIO 표기법: Beginning, Inside, Outside \n",
    "    - 각 토큰마다 태그 분이기 위해 사용 \n",
    "    - B : 개체명이 시작하는 단어에 'B-개체명' 태그\n",
    "    - I : 'B-개체명' 과 연결되는 단어일 때 'I-개체명' 태그\n",
    "    - O : 개체명 이외 모든 토큰에 태그\n",
    "\n",
    "- 개체명 인식 모델 학습하기 위해서는 토큰별로 BIO 태그 달린 데이터셋 필요\n",
    "    - 국립국어원 언어정보나눔터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 크기 : \n",
      " 3555\n",
      "0번째 샘플 문장 시퀀스 : \n",
      " ['1', '1', '2', '2', '2', '3', '3', '3', '4', '4', '5', '6', '7', '8', '9', '9', '10', '10', '10', '11']\n",
      "0번째 샘플 bio 태그 : \n",
      " ['NNG', 'SP', 'SL', 'NNG', 'NNG', 'SL', 'NNG', 'JKB', 'VV', 'ETM', 'NNP', 'MAJ', 'NNG', 'NNG', 'NNG', 'JKS', 'NNG', 'VV', 'EC', 'SF']\n",
      "샘플 문장 시퀀스 최대 길이 : 168\n",
      "샘플 문장 시퀀스 평균 길이 : 34.03909985935302\n",
      "BIO 태그 사전 크기 : 46\n",
      "단어 사전 크기 : 81\n",
      "[6, 6, 4, 4, 4, 3, 3, 3, 2, 2, 5, 7, 8, 9, 10, 10, 11, 11, 11, 12]\n",
      "[1, 16, 19, 1, 1, 19, 1, 6, 3, 7, 4, 33, 1, 1, 1, 15, 1, 3, 2, 11]\n",
      "학습 샘플 시퀀스 형상 :  (2844, 40)\n",
      "학습 샘플 레이블 형상 :  (2844, 40, 46)\n",
      "테스트 샘플 시퀀스 형상 :  (711, 40)\n",
      "테스트 샘플 레이블 형상 :  (711, 40, 46)\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 103s 989ms/step - loss: 2.9672 - accuracy: 0.2664\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 25s 1s/step - loss: 2.6472 - accuracy: 0.3246\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 23s 979ms/step - loss: 2.5930 - accuracy: 0.3476\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 23s 1s/step - loss: 2.5502 - accuracy: 0.3528\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 26s 1s/step - loss: 2.5212 - accuracy: 0.3526\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 28s 1s/step - loss: 2.4991 - accuracy: 0.3542\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 22s 935ms/step - loss: 2.4730 - accuracy: 0.3553\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 23s 989ms/step - loss: 2.4472 - accuracy: 0.3556\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 30s 1s/step - loss: 2.4068 - accuracy: 0.3563\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 29s 1s/step - loss: 2.3584 - accuracy: 0.3600\n",
      "23/23 [==============================] - 6s 130ms/step - loss: 2.2773 - accuracy: 0.3641\n",
      "평가 결과 :  0.364141047000885\n",
      "23/23 [==============================] - 6s 136ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ETM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NNB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NNP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NNG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JKS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: MAG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: XSV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: EC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VA seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SF seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JKO seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: EP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JKB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: XSN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: MM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VCP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ETN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SW seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JKG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: EF seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: XSA seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VX seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: XR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: XPN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: MAJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JKC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JKQ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SO seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: VCN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SH seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: IC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JKV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NA seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: JBK seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Playdata\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       158\n",
      "          AG       0.00      0.00      0.00       223\n",
      "          AJ       0.00      0.00      0.00        44\n",
      "          BK       0.00      0.00      0.00         1\n",
      "           C       0.42      0.06      0.10      1303\n",
      "          CN       0.00      0.00      0.00        10\n",
      "          CP       0.00      0.00      0.00       231\n",
      "           F       0.10      0.88      0.18      1097\n",
      "           H       0.00      0.00      0.00         9\n",
      "          KB       0.00      0.00      0.00       895\n",
      "          KC       0.00      0.00      0.00         4\n",
      "          KG       0.00      0.00      0.00       313\n",
      "          KO       0.16      0.12      0.14       718\n",
      "          KQ       0.00      0.00      0.00         8\n",
      "          KS       0.12      0.02      0.03       376\n",
      "          KV       0.00      0.00      0.00         1\n",
      "           L       0.00      0.00      0.00       299\n",
      "           M       0.00      0.00      0.00        97\n",
      "           N       0.00      0.00      0.00      1010\n",
      "          NB       0.29      0.02      0.04       799\n",
      "          NG       0.16      0.09      0.11      3856\n",
      "          NP       0.27      0.09      0.14       888\n",
      "           O       0.00      0.00      0.00        12\n",
      "           P       0.57      0.38      0.46       873\n",
      "          PN       0.00      0.00      0.00        60\n",
      "           R       0.00      0.00      0.00       147\n",
      "           S       0.18      0.04      0.06       750\n",
      "          SA       0.00      0.00      0.00        78\n",
      "          SN       0.00      0.00      0.00       221\n",
      "          SV       0.39      0.03      0.06       627\n",
      "          TM       0.16      0.05      0.08       842\n",
      "          TN       0.00      0.00      0.00        62\n",
      "           V       0.36      0.16      0.22      1133\n",
      "           W       0.00      0.00      0.00       124\n",
      "           X       0.28      0.20      0.23       729\n",
      "\n",
      "   micro avg       0.15      0.13      0.14     17998\n",
      "   macro avg       0.10      0.06      0.05     17998\n",
      "weighted avg       0.20      0.13      0.11     17998\n",
      "\n",
      "F1-score: 14.1%\n",
      "새로운 유형의 시퀀스 :  [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "단어         예측된 NER\n",
      "--------------------------------------------------\n",
      "삼성전자       NNG  \n",
      "출시         NNG  \n",
      "스마트폰       NNG  \n",
      "오늘         NNG  \n",
      "애플         VV   \n",
      "아이폰에       EP   \n",
      "도전장        EF   \n",
      "내밀다.       SF   \n"
     ]
    }
   ],
   "source": [
    "# 양방향 LSTM 이용한 NER \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 학습 파일 불러오기\n",
    "def read_file(file_name):\n",
    "    sents = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for idx, l in enumerate(lines):\n",
    "            if l[0] == ';' and lines[idx + 1][0] == '$':\n",
    "                this_sent = []\n",
    "            elif l[0] == '$' and lines[idx - 1][0] == ';':\n",
    "                continue\n",
    "            elif l[0] == '\\n':\n",
    "                sents.append(this_sent)\n",
    "            else:\n",
    "                this_sent.append(tuple(l.split()))\n",
    "    return sents\n",
    "\n",
    "\n",
    "# 학습용 말뭉치 데이터를 불러옴\n",
    "corpus = read_file('./data/train.txt')\n",
    "\n",
    "# 말뭉치 데이터에서 단어와 BIO 태그만 불러와 학습용 데이터셋 생성\n",
    "# 단어와 BIO 태그만 이용해 학습용 데이터셋 생성\n",
    "# 0번째 원본 문장에서 분리된 단어 토큰들이 sentences 리스트에 저장\n",
    "# sentences 리스트에 저장된 단어 시퀀스에 해당하는 BIO 태그 정보들이 tags 리스트에 저장\n",
    "# sentences 리스트와 tags 리스트 크기는 동일\n",
    "# 단어 시퀀스 평균 길이값을 기준으로 시퀀스 패딩 크기 결정\n",
    "sentences, tags = [], []\n",
    "for t in corpus:\n",
    "    tagged_sentence = []\n",
    "    sentence, bio_tag = [], []\n",
    "    for w in t:\n",
    "        tagged_sentence.append((w[1], w[2]))\n",
    "        sentence.append(w[0])\n",
    "        bio_tag.append(w[2])\n",
    "\n",
    "    sentences.append(sentence)\n",
    "    tags.append(bio_tag)\n",
    "\n",
    "print(\"샘플 크기 : \\n\", len(sentences))\n",
    "print(\"0번째 샘플 문장 시퀀스 : \\n\", sentences[0])\n",
    "print(\"0번째 샘플 bio 태그 : \\n\", tags[0])\n",
    "print(\"샘플 문장 시퀀스 최대 길이 :\", max(len(l) for l in sentences))\n",
    "print(\"샘플 문장 시퀀스 평균 길이 :\", (sum(map(len, sentences))/len(sentences)))\n",
    "\n",
    "\n",
    "# 토크나이저 정의\n",
    "# 위에서 만든 단어 시퀀스와 태그 시퀀스를 사전으로 만들기 위해 토크나이저 정의하고 fit_on_texts() 함수 호출 \n",
    "sent_tokenizer = preprocessing.text.Tokenizer(oov_token='OOV') # 첫 번째 인덱스에는 OOV 사용(out of vocabulary) - 단어 사전에 포함하지 않는 단어 \n",
    "sent_tokenizer.fit_on_texts(sentences)  # fit_on_texts() 문자 데이터 전달 받아 리스트 형태로 변환\n",
    "tag_tokenizer = preprocessing.text.Tokenizer(lower=False) # 태그 정보는 lower= False 소문자로 변환하지 않는다.\n",
    "tag_tokenizer.fit_on_texts(tags)\n",
    "\n",
    "# 단어 사전 및 태그 사전 크기\n",
    "# 생성된 사전 리스트를 이용해 단어와 태그 사전의 크기 정의\n",
    "vocab_size = len(sent_tokenizer.word_index) + 1\n",
    "tag_size = len(tag_tokenizer.word_index) + 1\n",
    "print(\"BIO 태그 사전 크기 :\", tag_size)\n",
    "print(\"단어 사전 크기 :\", vocab_size)\n",
    "\n",
    "# 학습용 단어 시퀀스 생성\n",
    "# 사전 데이터를 시퀀스 번호 형태로 인코딩\n",
    "x_train = sent_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tag_tokenizer.texts_to_sequences(tags)\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "# index to word / index to NER 정의\n",
    "index_to_word = sent_tokenizer.index_word # 시퀀스 인덱스를 단어로 변환하기 위해 사용\n",
    "index_to_ner = tag_tokenizer.index_word # 시퀀스 인덱스를 NER로 변환하기 위해 사용\n",
    "index_to_ner[0] = 'PAD'\n",
    "\n",
    "# 시퀀스 패딩 처리\n",
    "# 개체명 인식 모델의 입출력 벡터 크기를 동일하게 맞추기 위해 시퀀스 패딩 작업\n",
    "# 벡터 크기를 위-위에서 계산한 단어 시퀀스 평균 길이보다 넉넉하게 40으로 정의\n",
    "max_len = 40\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, padding='post', maxlen=max_len)\n",
    "y_train = preprocessing.sequence.pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터를 8:2 비율로 분리\n",
    "# sklearn.model_selection 모듈 train_test_split() 함수 이용해 학습용, 테스트용 데이터셋을 8:2 비율로 분리 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=.2, random_state=0)\n",
    "\n",
    "# 출력 데이터를 원-핫 인코딩\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=tag_size)\n",
    "\n",
    "print(\"학습 샘플 시퀀스 형상 : \", x_train.shape)\n",
    "print(\"학습 샘플 레이블 형상 : \", y_train.shape)\n",
    "print(\"테스트 샘플 시퀀스 형상 : \", x_test.shape)\n",
    "print(\"테스트 샘플 레이블 형상 : \", y_test.shape)\n",
    "\n",
    "# 모델 정의(Bi-LSTM)\n",
    "# 개체 인식 모델 순차 모델 방식 구현\n",
    "# tag_size 만큼 출력 뉴런에서 제일 확률 높은 출력값 1개 선택하는 문제라 모델 출력 계층 활성화 함수로 softmax 사용\n",
    "# 손실함수 categorical_crossentropy 사용\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=30, input_length=max_len, mask_zero=True))  # 단어 임베딩 \n",
    "model.add(Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25)))  # 양방향 LSTM \n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))  # NER 태그분류 \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "print(\"평가 결과 : \", model.evaluate(x_test, y_test)[1])  # 학습 평가 결과 확인\n",
    "\n",
    "\n",
    "# 시퀀스를 NER 태그로 변환\n",
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "        temp = []\n",
    "        for pred in sequence:\n",
    "            pred_index = np.argmax(pred)\n",
    "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(temp)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 테스트 데이터셋의 NER 예측\n",
    "# F1스코어 계산하기 위해 모델 predict() 함수 통해 테스트용 데이터셋 결과 예측 \n",
    "# 해당 함수 결과로 예측된 NER 태그 정보가 담긴 넘파이 배열이 반환\n",
    "y_predicted = model.predict(x_test) # (711, 40) => model => (711, 40, 8)\n",
    "pred_tags = sequences_to_tag(y_predicted) # 예측된 NER\n",
    "test_tags = sequences_to_tag(y_test) # 실제 NER\n",
    "\n",
    "# F1 스코어 계산을 위해 사용\n",
    "# seqeval.metrics 모듈의 classification_report() 함수 통해 NER 태그별로 계산된 정밀도 재현율 F!스코어 출력\n",
    "# f1스코어만 불러올 수도 있음 - f1_score() 함수 \n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "print(classification_report(test_tags, pred_tags))\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "\n",
    "\n",
    "# 새로운 유형의 문장 NER 예측\n",
    "word_to_index = sent_tokenizer.word_index\n",
    "new_sentence = '삼성전자 출시 스마트폰 오늘 애플 아이폰에 도전장 내밀다.'.split()\n",
    "new_x = []\n",
    "for w in new_sentence:\n",
    "    try:\n",
    "        new_x.append(word_to_index.get(w, 1))\n",
    "    except KeyError:\n",
    "        # 모르는 단어의 경우 OOV\n",
    "        new_x.append(word_to_index['OOV'])\n",
    "\n",
    "print(\"새로운 유형의 시퀀스 : \", new_x)\n",
    "new_padded_seqs = preprocessing.sequence.pad_sequences([new_x], padding=\"post\", value=0, maxlen=max_len)\n",
    "\n",
    "# NER 예측\n",
    "p = model.predict(np.array([new_padded_seqs[0]]))\n",
    "p = np.argmax(p, axis=-1) # 예측된 NER 인덱스값 추출\n",
    "print(\"{:10} {:5}\".format(\"단어\", \"예측된 NER\"))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for w, pred in zip(new_sentence, p[0]):\n",
    "    print(\"{:10} {:5}\".format(w, index_to_ner[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 챗봇 학습툴 만들기 \n",
    "\n",
    "### 7.1 MySQL \n",
    "\n",
    "- 접근하기 좋은 데이터 베이스 \n",
    "- 챗봇 시스템 학습 데이터 관리 위해 MySQL 사용\n",
    "- 파이썬에서 MySQL 사용하기 \n",
    "\n",
    "### 7.2 파이썬으로 데이터베이스 연동하기 \n",
    "\n",
    "- MySQL 사용 - MySQL 클라이언트 라이브러리 \n",
    "- 쉽게 사용하려면 고수준 API 지원, 무료 PyMySQL 모듈 - MySQL, Maria DB 지원\n",
    "- SQL 명령어 종류 \n",
    "    - select : 데이터 테이블에서 데이터 조회 \n",
    "    - insert : 데이터 테이블에서 데이터 삽입 \n",
    "    - update : 데이터 테이블의 데이터를 변경 \n",
    "    - delete : 데이터 테이블의 데이터 삭제 \n",
    "\n",
    "- PyMySQL 모듈은 MySQL DB 시스템에 연결 및 데이터 조작 할 수 있는 다양한 함수 제공     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 데이터베이스 연결하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB 연결 성공\n",
      "DB 연결 닫기 성공\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "\n",
    "# DB_HOST=127.0.0.1\n",
    "# DB_PORT=3306\n",
    "# DB_DATABASE=homestead\n",
    "# DB_USERNAME=homestead\n",
    "# DB_PASSWORD=secret\n",
    "\n",
    "db = None\n",
    "try:\n",
    "    # DB 호스트 정보에 맞게 입력해주세요\n",
    "    db = pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        passwd='1234',\n",
    "        db='chatbot',\n",
    "        charset='utf8'\n",
    "    )\n",
    "    print(\"DB 연결 성공\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    if db is not None:\n",
    "        db.close()\n",
    "        print(\"DB 연결 닫기 성공\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 데이터 조작하기 \n",
    "\n",
    "- DB 테이블 생성, 데이터 삽입, 조회, 변경, 삭제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 테이블 생성 \n",
    "\n",
    "import pymysql \n",
    "\n",
    "db = None \n",
    "\n",
    "try:\n",
    "    db = pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        passwd='1234',\n",
    "        db='chatbot',\n",
    "        charset='utf8'\n",
    "    )\n",
    "    \n",
    "    # 테이블 생성 sql 정의 \n",
    "    sql = '''\n",
    "    CREATE TABLE tb_student (\n",
    "        id int primary key auto_increment not null,\n",
    "        name varchar(32),\n",
    "        age int, \n",
    "        address varchar(32)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8\n",
    "    '''\n",
    "    \n",
    "    # 테이블 생성 \n",
    "    # 연결 DB 와 상호작용하려면 cursor 객체 필요. \n",
    "    # cursor 객체는 임의로 생성할 수 없으며 DB 호슽에 연결된 객체(db) 의 cursor() 함수로 cursor 객체를 받아와야 한다. \n",
    "    # cursor 객체 execute() 함수로 SQL 구문 실행.\n",
    "    # with 구문 내에서 cursor 객체 사용하기 때문에 사용 후에는 자동으로 메모리 해제.\n",
    "    with db.cursor() as cursor:\n",
    "        cursor.execute(sql) \n",
    "        \n",
    "except Exception as e:\n",
    "    print(e) \n",
    "    \n",
    "finally:\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL 데이터 삽입 \n",
    "import pymysql \n",
    "\n",
    "db = None \n",
    "try:\n",
    "    db = pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        passwd='1234',\n",
    "        db='chatbot',\n",
    "        charset='utf8'\n",
    "    )\n",
    "    \n",
    "    # 데이터 삽입 sql 정의\n",
    "    # tb_student 테이블에 데이터 삽입 하기 위해 정의한 SQL 구문\n",
    "    sql = '''\n",
    "    INSERT INTO tb_student(name, age, address) values('min', 40, 'Korea')\n",
    "    '''\n",
    "    \n",
    "    # 데이터 삽입 \n",
    "    # cursor 객체 execute() 함수로 SQL구문 실행.\n",
    "    with db.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "    db.commit()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    if db is not None:\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변경 \n",
    "# 데이터 수정 sql 정의\n",
    "\n",
    "import pymysql \n",
    "\n",
    "db = None \n",
    "try:\n",
    "    db = pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        passwd='1234',\n",
    "        db='chatbot',\n",
    "        charset='utf8'\n",
    "    )\n",
    "\n",
    "    # 데이터 수정 sql 정의\n",
    "    id = 1  # 데이터 id (PK)\n",
    "    sql = '''\n",
    "        UPDATE tb_student set name=\"케이\", age=36 where id=%d\n",
    "        ''' % id\n",
    "\n",
    "    # 데이터 수정\n",
    "    with db.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "    db.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    if db is not None:\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 삭제\n",
    "import pymysql \n",
    "\n",
    "db = None \n",
    "try:\n",
    "    db = pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        passwd='1234',\n",
    "        db='chatbot',\n",
    "        charset='utf8'\n",
    "    )\n",
    "\n",
    "    # 데이터 삭제 sql 정의\n",
    "    id = 1  # 데이터 id (PK)\n",
    "    sql = '''\n",
    "        DELETE from tb_student where id=%d\n",
    "        ''' % id\n",
    "\n",
    "    # 데이터 수정\n",
    "    with db.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "    db.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    if db is not None:\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 2, 'name': 'min', 'age': 40, 'address': 'Korea'}, {'id': 3, 'name': 'Kei', 'age': 36, 'address': 'PUSAN'}, {'id': 4, 'name': 'Tony', 'age': 34, 'address': 'PUSAN'}, {'id': 5, 'name': 'Jaeyoo', 'age': 39, 'address': 'GWANGJU'}]\n",
      "Grace 28\n",
      "   id    name  age  address\n",
      "0   2     min   40    Korea\n",
      "1   3     Kei   36    PUSAN\n",
      "2   4    Tony   34    PUSAN\n",
      "3   5  Jaeyoo   39  GWANGJU\n"
     ]
    }
   ],
   "source": [
    "# 데이터 조회 \n",
    "import pymysql   \n",
    "import pandas as pd \n",
    "\n",
    "db = None \n",
    "try:\n",
    "    db = pymysql.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        passwd='1234',\n",
    "        db='chatbot',\n",
    "        charset='utf8'\n",
    "    )\n",
    "    \n",
    "    # 데이터 db에 추가\n",
    "    # 학생 정보 저장된 딕셔너리 데이터 정의\n",
    "    students = [\n",
    "        {'name': 'Kei', 'age': 36, 'address' : 'PUSAN'},\n",
    "        {'name': 'Tony', 'age': 34, 'address': 'PUSAN'},\n",
    "        {'name': 'Jaeyoo', 'age': 39, 'address': 'GWANGJU'},\n",
    "        {'name': 'Grace', 'age': 28, 'address': 'SEOUL'},\n",
    "        {'name': 'Jenny', 'age': 27, 'address': 'SEOUL'},\n",
    "    ]\n",
    "    for s in students:\n",
    "        with db.cursor() as cursor:\n",
    "            sql = '''\n",
    "            insert tb_student(name, age, address) values(\"%s\",\"%d\",\"%s\") \n",
    "            ''' % (s['name'], s['age'], s['address'])    # % (s['name'], d['age'], s['address']  Error\n",
    "            cursor.execute(sql) \n",
    "    db.commit()  # 커밋 \n",
    "    \n",
    "    # 30대 학생만 조회 \n",
    "    # select 명령 위한 SQL 구문 cursor.execute() 함수로 실행하고 검색 결과를 cursro.fetchall() 함수 호출해 받아옴  \n",
    "    # fetchall() 함수는 select 구문으로 조회한 모든 데이터 불러오는 함수 = 딕셔너리 형태 \n",
    "    cond_age = 30 \n",
    "    with db.cursor(pymysql.cursors.DictCursor) as cursor:\n",
    "        sql='''\n",
    "        select * from tb_student where age > %d\n",
    "        ''' % cond_age \n",
    "        cursor.execute(sql) \n",
    "        results = cursor.fetchall() \n",
    "    print(results) \n",
    "    \n",
    "    # 이름 검색 \n",
    "    # 검색 결과 1건. cursor.fetchone() 함수 호출. 1개의 행만 불러옴\n",
    "    cond_name = 'Grace'\n",
    "    with db.cursor(pymysql.cursors.DictCursor) as cursor: \n",
    "        sql = ''' \n",
    "            select * from tb_student where name =\"%s\"\n",
    "        ''' % cond_name \n",
    "        cursor.execute(sql) \n",
    "        result = cursor.fetchone() \n",
    "    print(result['name'], result['age'])   # 조회 결과에서 name, age 데이터만 출력\n",
    "    \n",
    "    # pandas 데이터 프레임으로 표현 \n",
    "    # DB 조회 결과를 판다스 데이터 객체로 변환해 편리하게 데이터 처리 가능\n",
    "    df = pd.DataFrame(results) \n",
    "    print(df) \n",
    "    \n",
    "except Exception as e:\n",
    "    print(e) \n",
    "    \n",
    "finally:\n",
    "    if db is not None:\n",
    "        db.close() \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 챗봇 학습툴 만들기 \n",
    "\n",
    "- 챗봇 학습 데이터 관리하는 툴\n",
    "- 목표: 학습 데이터를 DB에 저장 했을 때 실시간으로 챗봇 시스템에 적용 될 수 있도록 제작 하는 것\n",
    "    - 챗봇이 이해할 수 있는 질문 정보와 해당 답변 데이터 관리하기 위한 툴 필요\n",
    "\n",
    "- 토이 챗봇 과정\n",
    "    1. 입력되는 문장을 자연어 처리해 해당 문장 의도, 개체명, 키워드 정보 추출 \n",
    "    2. 엔진에서 해석한 결과 이용해 학습 DB 내용 검색 \n",
    "        - 해석결과(의도, 개체명) 매칭 되는 답변 정보가 DB 에 존재하면 데이터 불러와 사용자에게 답변 제공\n",
    "\n",
    "- QNA 챗봇    \n",
    "    - 대화 용도 아님\n",
    "    - 특정 분야 FAQ 사람 대신 처리 \n",
    "    - 질문 해석 결과에 연관된 답변 데이터를 DB에 저장할 필요 있음\n",
    "    - 스몰토크 챗봇 모델 X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b6f0d8d647a14ce7aec9650edf6792f5fc61b159b6795cf61c93c7b5c41aef5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
